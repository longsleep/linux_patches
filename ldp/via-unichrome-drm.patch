---
 drivers/char/drm/via_3d_reg.h   |   12 -
 drivers/char/drm/via_dma.c      |  353 +++++++++++++++++++++++++++-------------
 drivers/char/drm/via_dmablit.c  |  325 +++++++++++++++++++++---------------
 drivers/char/drm/via_dmablit.h  |   22 +-
 drivers/char/drm/via_drm.h      |  142 ++++++++++------
 drivers/char/drm/via_drv.c      |   13 +
 drivers/char/drm/via_drv.h      |   93 ++++++----
 drivers/char/drm/via_irq.c      |   66 ++++---
 drivers/char/drm/via_map.c      |   75 +++++++-
 drivers/char/drm/via_mm.c       |  249 ++++++++++++++++++++++------
 drivers/char/drm/via_verifier.c |  269 +++++++++++++++---------------
 drivers/char/drm/via_verifier.h |   64 +++----
 drivers/char/drm/via_video.c    |   70 ++++---
 13 files changed, 1111 insertions(+), 642 deletions(-)

--- a/drivers/char/drm/via_3d_reg.h
+++ b/drivers/char/drm/via_3d_reg.h
@@ -1605,18 +1605,18 @@
 #define HC_ACMD_H4COUNT_MASK    0x01fffe00
 #define HC_ACMD_H4COUNT_SHIFT   9
 
-/********************************************************************************
+/******************************************************************************
 ** Define Header
-********************************************************************************/
+*******************************************************************************/
 #define HC_HEADER2		0xF210F110
 
-/********************************************************************************
+/******************************************************************************
 ** Define Dummy Value
-********************************************************************************/
+*******************************************************************************/
 #define HC_DUMMY		0xCCCCCCCC
-/********************************************************************************
+/******************************************************************************
 ** Define for DMA use
-********************************************************************************/
+*******************************************************************************/
 #define HALCYON_HEADER2     0XF210F110
 #define HALCYON_FIRECMD     0XEE100000
 #define HALCYON_FIREMASK    0XFFF00000
--- a/drivers/char/drm/via_dmablit.c
+++ b/drivers/char/drm/via_dmablit.c
@@ -30,8 +30,8 @@
 /*
  * Unmaps the DMA mappings.
  * FIXME: Is this a NoOp on x86? Also
- * FIXME: What happens if this one is called and a pending blit has previously done
- * the same DMA mappings?
+ * FIXME: What happens if this one is called and a pending
+ * blit has previously done the same DMA mappings?
  */
 
 #include "drmP.h"
@@ -45,12 +45,12 @@
 #define VIA_PGOFF(x)	    (((unsigned long)(x)) & ~PAGE_MASK)
 #define VIA_PFN(x)	      ((unsigned long)(x) >> PAGE_SHIFT)
 
-typedef struct _drm_via_descriptor {
+struct drm_via_descriptor {
 	uint32_t mem_addr;
 	uint32_t dev_addr;
 	uint32_t size;
 	uint32_t next;
-} drm_via_descriptor_t;
+} ;
 
 
 /*
@@ -60,24 +60,26 @@ typedef struct _drm_via_descriptor {
 
 
 static void
-via_unmap_blit_from_device(struct pci_dev *pdev, drm_via_sg_info_t *vsg)
+via_unmap_blit_from_device(struct pci_dev *pdev, struct drm_via_sg_info *vsg)
 {
 	int num_desc = vsg->num_desc;
 	unsigned cur_descriptor_page = num_desc / vsg->descriptors_per_page;
 	unsigned descriptor_this_page = num_desc % vsg->descriptors_per_page;
-	drm_via_descriptor_t *desc_ptr = vsg->desc_pages[cur_descriptor_page] +
-		descriptor_this_page;
+	struct drm_via_descriptor *desc_ptr =
+		vsg->desc_pages[cur_descriptor_page] + descriptor_this_page;
 	dma_addr_t next = vsg->chain_start;
 
-	while(num_desc--) {
+	while (num_desc--) {
 		if (descriptor_this_page-- == 0) {
 			cur_descriptor_page--;
 			descriptor_this_page = vsg->descriptors_per_page - 1;
 			desc_ptr = vsg->desc_pages[cur_descriptor_page] +
 				descriptor_this_page;
 		}
-		dma_unmap_single(&pdev->dev, next, sizeof(*desc_ptr), DMA_TO_DEVICE);
-		dma_unmap_page(&pdev->dev, desc_ptr->mem_addr, desc_ptr->size, vsg->direction);
+		dma_unmap_single(&pdev->dev, next, sizeof(*desc_ptr),
+			DMA_TO_DEVICE);
+		dma_unmap_page(&pdev->dev, desc_ptr->mem_addr, desc_ptr->size,
+			vsg->direction);
 		next = (dma_addr_t) desc_ptr->next;
 		desc_ptr--;
 	}
@@ -85,15 +87,16 @@ via_unmap_blit_from_device(struct pci_de
 
 /*
  * If mode = 0, count how many descriptors are needed.
- * If mode = 1, Map the DMA pages for the device, put together and map also the descriptors.
- * Descriptors are run in reverse order by the hardware because we are not allowed to update the
- * 'next' field without syncing calls when the descriptor is already mapped.
+ * If mode = 1, Map the DMA pages for the device, put together and
+ * map also the descriptors. Descriptors are run in reverse order
+ * by the hardware because we are not allowed to update the 'next'
+ * field without syncing calls when the descriptor is already mapped.
  */
 
 static void
 via_map_blit_for_device(struct pci_dev *pdev,
-		   const drm_via_dmablit_t *xfer,
-		   drm_via_sg_info_t *vsg,
+		   const struct drm_via_dmablit *xfer,
+		   struct drm_via_sg_info *vsg,
 		   int mode)
 {
 	unsigned cur_descriptor_page = 0;
@@ -108,7 +111,7 @@ via_map_blit_for_device(struct pci_dev *
 	int num_desc = 0;
 	int cur_line;
 	dma_addr_t next = 0 | VIA_DMA_DPR_EC;
-	drm_via_descriptor_t *desc_ptr = NULL;
+	struct drm_via_descriptor *desc_ptr = NULL;
 
 	if (mode == 1)
 		desc_ptr = vsg->desc_pages[cur_descriptor_page];
@@ -121,26 +124,29 @@ via_map_blit_for_device(struct pci_dev *
 
 		while (line_len > 0) {
 
-			remaining_len = min(PAGE_SIZE-VIA_PGOFF(cur_mem), line_len);
+			remaining_len = min(PAGE_SIZE-VIA_PGOFF(cur_mem),
+				line_len);
 			line_len -= remaining_len;
 
 			if (mode == 1) {
 				desc_ptr->mem_addr =
 					dma_map_page(&pdev->dev,
-						     vsg->pages[VIA_PFN(cur_mem) -
-								VIA_PFN(first_addr)],
-						     VIA_PGOFF(cur_mem), remaining_len,
-						     vsg->direction);
+					vsg->pages[VIA_PFN(cur_mem) -
+					VIA_PFN(first_addr)],
+					VIA_PGOFF(cur_mem), remaining_len,
+					vsg->direction);
 				desc_ptr->dev_addr = cur_fb;
 
 				desc_ptr->size = remaining_len;
 				desc_ptr->next = (uint32_t) next;
-				next = dma_map_single(&pdev->dev, desc_ptr, sizeof(*desc_ptr),
-						      DMA_TO_DEVICE);
+				next = dma_map_single(&pdev->dev, desc_ptr,
+					sizeof(*desc_ptr), DMA_TO_DEVICE);
 				desc_ptr++;
-				if (++num_descriptors_this_page >= vsg->descriptors_per_page) {
+				if (++num_descriptors_this_page >=
+					vsg->descriptors_per_page) {
 					num_descriptors_this_page = 0;
-					desc_ptr = vsg->desc_pages[++cur_descriptor_page];
+					desc_ptr =
+					vsg->desc_pages[++cur_descriptor_page];
 				}
 			}
 
@@ -162,30 +168,31 @@ via_map_blit_for_device(struct pci_dev *
 
 /*
  * Function that frees up all resources for a blit. It is usable even if the
- * blit info has only been partially built as long as the status enum is consistent
- * with the actual status of the used resources.
+ * blit info has only been partially built as long as the status enum is
+ * consistent with the actual status of the used resources.
  */
 
-
 static void
-via_free_sg_info(struct pci_dev *pdev, drm_via_sg_info_t *vsg)
+via_free_sg_info(struct pci_dev *pdev, struct drm_via_sg_info *vsg)
 {
 	struct page *page;
 	int i;
 
-	switch(vsg->state) {
+	switch (vsg->state) {
 	case dr_via_device_mapped:
 		via_unmap_blit_from_device(pdev, vsg);
 	case dr_via_desc_pages_alloc:
-		for (i=0; i<vsg->num_desc_pages; ++i) {
+		for (i = 0; i < vsg->num_desc_pages; ++i) {
 			if (vsg->desc_pages[i] != NULL)
 			  free_page((unsigned long)vsg->desc_pages[i]);
 		}
 		kfree(vsg->desc_pages);
 	case dr_via_pages_locked:
-		for (i=0; i<vsg->num_pages; ++i) {
-			if ( NULL != (page = vsg->pages[i])) {
-				if (! PageReserved(page) && (DMA_FROM_DEVICE == vsg->direction))
+		for (i = 0; i < vsg->num_pages; ++i) {
+			page = vsg->pages[i];
+			if (NULL != page) {
+				if (!PageReserved(page) &&
+					(DMA_FROM_DEVICE == vsg->direction))
 					SetPageDirty(page);
 				page_cache_release(page);
 			}
@@ -207,36 +214,44 @@ via_free_sg_info(struct pci_dev *pdev, d
  */
 
 static void
-via_fire_dmablit(struct drm_device *dev, drm_via_sg_info_t *vsg, int engine)
+via_fire_dmablit(struct drm_device *dev, struct drm_via_sg_info *vsg,
+		 int engine)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *)dev->dev_private;
 
 	VIA_WRITE(VIA_PCI_DMA_MAR0 + engine*0x10, 0);
 	VIA_WRITE(VIA_PCI_DMA_DAR0 + engine*0x10, 0);
-	VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_DD | VIA_DMA_CSR_TD |
-		  VIA_DMA_CSR_DE);
-	VIA_WRITE(VIA_PCI_DMA_MR0  + engine*0x04, VIA_DMA_MR_CM | VIA_DMA_MR_TDIE);
+	VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04,
+		VIA_DMA_CSR_DD | VIA_DMA_CSR_TD | VIA_DMA_CSR_DE);
+	VIA_WRITE(VIA_PCI_DMA_MR0  + engine*0x04,
+		VIA_DMA_MR_CM | VIA_DMA_MR_TDIE);
 	VIA_WRITE(VIA_PCI_DMA_BCR0 + engine*0x10, 0);
 	VIA_WRITE(VIA_PCI_DMA_DPR0 + engine*0x10, vsg->chain_start);
 	DRM_WRITEMEMORYBARRIER();
-	VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_DE | VIA_DMA_CSR_TS);
+	VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04,
+		VIA_DMA_CSR_DE | VIA_DMA_CSR_TS);
 	VIA_READ(VIA_PCI_DMA_CSR0 + engine*0x04);
 }
 
 /*
- * Obtain a page pointer array and lock all pages into system memory. A segmentation violation will
- * occur here if the calling user does not have access to the submitted address.
+ * Obtain a page pointer array and lock all pages into system memory.
+ * A segmentation violation will occur here if the calling user
+ * does not have access to the submitted address.
  */
 
 static int
-via_lock_all_dma_pages(drm_via_sg_info_t *vsg,  drm_via_dmablit_t *xfer)
+via_lock_all_dma_pages(struct drm_via_sg_info *vsg,
+		       struct drm_via_dmablit *xfer)
 {
 	int ret;
 	unsigned long first_pfn = VIA_PFN(xfer->mem_addr);
-	vsg->num_pages = VIA_PFN(xfer->mem_addr + (xfer->num_lines * xfer->mem_stride -1)) -
+	vsg->num_pages = VIA_PFN(xfer->mem_addr +
+		(xfer->num_lines * xfer->mem_stride - 1)) -
 		first_pfn + 1;
-
-	if (NULL == (vsg->pages = vmalloc(sizeof(struct page *) * vsg->num_pages)))
+	vsg->pages = vmalloc(sizeof(struct page *) *
+		vsg->num_pages);
+	if (NULL == vsg->pages)
 		return -ENOMEM;
 	memset(vsg->pages, 0, sizeof(struct page *) * vsg->num_pages);
 	down_read(&current->mm->mmap_sem);
@@ -259,38 +274,42 @@ via_lock_all_dma_pages(drm_via_sg_info_t
 }
 
 /*
- * Allocate DMA capable memory for the blit descriptor chain, and an array that keeps track of the
- * pages we allocate. We don't want to use kmalloc for the descriptor chain because it may be
- * quite large for some blits, and pages don't need to be contingous.
+ * Allocate DMA capable memory for the blit descriptor chain, and an
+ * array that keeps track of the pages we allocate. We don't want
+ * to use kmalloc for the descriptor chain because it may be
  */
 
 static int
-via_alloc_desc_pages(drm_via_sg_info_t *vsg)
+via_alloc_desc_pages(struct drm_via_sg_info *vsg)
 {
 	int i;
 
-	vsg->descriptors_per_page = PAGE_SIZE / sizeof( drm_via_descriptor_t);
+	vsg->descriptors_per_page = PAGE_SIZE /
+		sizeof(struct drm_via_descriptor);
 	vsg->num_desc_pages = (vsg->num_desc + vsg->descriptors_per_page - 1) /
 		vsg->descriptors_per_page;
-
-	if (NULL ==  (vsg->desc_pages = kcalloc(vsg->num_desc_pages, sizeof(void *), GFP_KERNEL)))
+	vsg->desc_pages = kcalloc(vsg->num_desc_pages,
+		sizeof(void *), GFP_KERNEL);
+	if (NULL == vsg->desc_pages)
 		return -ENOMEM;
 
 	vsg->state = dr_via_desc_pages_alloc;
-	for (i=0; i<vsg->num_desc_pages; ++i) {
-		if (NULL == (vsg->desc_pages[i] =
-			     (drm_via_descriptor_t *) __get_free_page(GFP_KERNEL)))
+	for (i = 0; i < vsg->num_desc_pages; ++i) {
+		vsg->desc_pages[i] =
+		(struct drm_via_descriptor *) __get_free_page(GFP_KERNEL);
+		if (NULL == vsg->desc_pages[i])
 			return -ENOMEM;
 	}
-	DRM_DEBUG("Allocated %d pages for %d descriptors.\n", vsg->num_desc_pages,
-		  vsg->num_desc);
+	DRM_DEBUG("Allocated %d pages for %d descriptors.\n", \
+		vsg->num_desc_pages, vsg->num_desc);
 	return 0;
 }
 
 static void
 via_abort_dmablit(struct drm_device *dev, int engine)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *)dev->dev_private;
 
 	VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_TA);
 }
@@ -298,32 +317,36 @@ via_abort_dmablit(struct drm_device *dev
 static void
 via_dmablit_engine_off(struct drm_device *dev, int engine)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *)dev->dev_private;
 
-	VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_TD | VIA_DMA_CSR_DD);
+	VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04,
+		VIA_DMA_CSR_TD | VIA_DMA_CSR_DD);
 }
 
 
 
 /*
- * The dmablit part of the IRQ handler. Trying to do only reasonably fast things here.
- * The rest, like unmapping and freeing memory for done blits is done in a separate workqueue
- * task. Basically the task of the interrupt handler is to submit a new blit to the engine, while
+ * The dmablit part of the IRQ handler. Trying to do only reasonably
+ * fast things here. The rest, like unmapping and freeing memory for
+ * done blits is done in a separate workqueue task. Basically the
+ * task of the interrupt handler is to submit a new blit to the engine, while
  * the workqueue task takes care of processing associated with the old blit.
  */
 
 void
 via_dmablit_handler(struct drm_device *dev, int engine, int from_irq)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;
-	drm_via_blitq_t *blitq = dev_priv->blit_queues + engine;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *)dev->dev_private;
+	struct drm_via_blitq *blitq = dev_priv->blit_queues + engine;
 	int cur;
 	int done_transfer;
-	unsigned long irqsave=0;
+	unsigned long irqsave = 0;
 	uint32_t status = 0;
 
-	DRM_DEBUG("DMA blit handler called. engine = %d, from_irq = %d, blitq = 0x%lx\n",
-		  engine, from_irq, (unsigned long) blitq);
+	DRM_DEBUG("DMA blit handler called. engine = %d, from_irq = %d, "
+		"blitq = 0x%lx\n", engine, from_irq, (unsigned long) blitq);
 
 	if (from_irq) {
 		spin_lock(&blitq->blit_lock);
@@ -332,8 +355,10 @@ via_dmablit_handler(struct drm_device *d
 	}
 
 	done_transfer = blitq->is_active &&
-	  (( status = VIA_READ(VIA_PCI_DMA_CSR0 + engine*0x04)) & VIA_DMA_CSR_TD);
-	done_transfer = done_transfer || ( blitq->aborting && !(status & VIA_DMA_CSR_DE));
+	  ((status = VIA_READ(VIA_PCI_DMA_CSR0 + engine*0x04)) &
+	  VIA_DMA_CSR_TD);
+	done_transfer = done_transfer || (blitq->aborting &&
+		!(status & VIA_DMA_CSR_DE));
 
 	cur = blitq->cur;
 	if (done_transfer) {
@@ -357,7 +382,8 @@ via_dmablit_handler(struct drm_device *d
 		blitq->aborting = 0;
 		schedule_work(&blitq->wq);
 
-	} else if (blitq->is_active && time_after_eq(jiffies, blitq->end)) {
+	} else if (blitq->is_active &&
+		   time_after_eq(jiffies, blitq->end)) {
 
 		/*
 		 * Abort transfer after one second.
@@ -378,9 +404,8 @@ via_dmablit_handler(struct drm_device *d
 			if (!timer_pending(&blitq->poll_timer))
 				mod_timer(&blitq->poll_timer, jiffies + 1);
 		} else {
-			if (timer_pending(&blitq->poll_timer)) {
+			if (timer_pending(&blitq->poll_timer))
 				del_timer(&blitq->poll_timer);
-			}
 			via_dmablit_engine_off(dev, engine);
 		}
 	}
@@ -399,7 +424,8 @@ via_dmablit_handler(struct drm_device *d
  */
 
 static int
-via_dmablit_active(drm_via_blitq_t *blitq, int engine, uint32_t handle, wait_queue_head_t **queue)
+via_dmablit_active(struct drm_via_blitq *blitq, int engine, uint32_t handle,
+wait_queue_head_t **queue)
 {
 	unsigned long irqsave;
 	uint32_t slot;
@@ -415,10 +441,10 @@ via_dmablit_active(drm_via_blitq_t *blit
 		((blitq->cur_blit_handle - handle) <= (1 << 23));
 
 	if (queue && active) {
-		slot = handle - blitq->done_blit_handle + blitq->cur -1;
-		if (slot >= VIA_NUM_BLIT_SLOTS) {
+		slot = handle - blitq->done_blit_handle + blitq->cur - 1;
+		if (slot >= VIA_NUM_BLIT_SLOTS)
 			slot -= VIA_NUM_BLIT_SLOTS;
-		}
+
 		*queue = blitq->blit_queue + slot;
 	}
 
@@ -435,28 +461,32 @@ static int
 via_dmablit_sync(struct drm_device *dev, uint32_t handle, int engine)
 {
 
-	drm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;
-	drm_via_blitq_t *blitq = dev_priv->blit_queues + engine;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *)dev->dev_private;
+	struct drm_via_blitq *blitq = dev_priv->blit_queues + engine;
 	wait_queue_head_t *queue;
 	int ret = 0;
 
 	if (via_dmablit_active(blitq, engine, handle, &queue)) {
 		DRM_WAIT_ON(ret, *queue, 3 * DRM_HZ,
-			    !via_dmablit_active(blitq, engine, handle, NULL));
+			!via_dmablit_active(blitq, engine, handle, NULL));
 	}
-	DRM_DEBUG("DMA blit sync handle 0x%x engine %d returned %d\n",
-		  handle, engine, ret);
+	DRM_DEBUG("DMA blit sync handle 0x%x engine %d returned %d\n", \
+		handle, engine, ret);
 
 	return ret;
 }
 
 
 /*
- * A timer that regularly polls the blit engine in cases where we don't have interrupts:
- * a) Broken hardware (typically those that don't have any video capture facility).
- * b) Blit abort. The hardware doesn't send an interrupt when a blit is aborted.
- * The timer and hardware IRQ's can and do work in parallel. If the hardware has
- * irqs, it will shorten the latency somewhat.
+ * A timer that regularly polls the blit engine in cases where
+ * we don't have interrupts:
+ * a) Broken hardware (typically those that don't have any
+ *    video capture facility).
+ * b) Blit abort. The hardware doesn't send an interrupt
+ *    when a blit is aborted.
+ * The timer and hardware IRQ's can and do work in parallel.
+ * If the hardware has irqs, it will shorten the latency somewhat.
  */
 
 
@@ -464,10 +494,10 @@ via_dmablit_sync(struct drm_device *dev,
 static void
 via_dmablit_timer(unsigned long data)
 {
-	drm_via_blitq_t *blitq = (drm_via_blitq_t *) data;
+	struct drm_via_blitq *blitq = (struct drm_via_blitq *) data;
 	struct drm_device *dev = blitq->dev;
 	int engine = (int)
-		(blitq - ((drm_via_private_t *)dev->dev_private)->blit_queues);
+	(blitq - ((struct drm_via_private *)dev->dev_private)->blit_queues);
 
 	DRM_DEBUG("Polling timer called for engine %d, jiffies %lu\n", engine,
 		  (unsigned long) jiffies);
@@ -482,7 +512,7 @@ via_dmablit_timer(unsigned long data)
 		* to shorten abort latency. This is a little nasty.
 		*/
 
-	       via_dmablit_handler(dev, engine, 0);
+		via_dmablit_handler(dev, engine, 0);
 
 	}
 }
@@ -500,19 +530,21 @@ via_dmablit_timer(unsigned long data)
 static void
 via_dmablit_workqueue(struct work_struct *work)
 {
-	drm_via_blitq_t *blitq = container_of(work, drm_via_blitq_t, wq);
+	struct drm_via_blitq *blitq =
+		container_of(work, struct drm_via_blitq, wq);
 	struct drm_device *dev = blitq->dev;
 	unsigned long irqsave;
-	drm_via_sg_info_t *cur_sg;
+	struct drm_via_sg_info *cur_sg;
 	int cur_released;
 
 
-	DRM_DEBUG("Workqueue task called for blit engine %ld\n",(unsigned long)
-		  (blitq - ((drm_via_private_t *)dev->dev_private)->blit_queues));
+	DRM_DEBUG("Workqueue task called for blit engine %ld\n",
+		(unsigned long)(blitq -
+		((struct drm_via_private *)dev->dev_private)->blit_queues));
 
 	spin_lock_irqsave(&blitq->blit_lock, irqsave);
 
-	while(blitq->serviced != blitq->cur) {
+	while (blitq->serviced != blitq->cur) {
 
 		cur_released = blitq->serviced++;
 
@@ -546,13 +578,14 @@ via_dmablit_workqueue(struct work_struct
 void
 via_init_dmablit(struct drm_device *dev)
 {
-	int i,j;
-	drm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;
-	drm_via_blitq_t *blitq;
+	int i, j;
+	struct drm_via_private *dev_priv =
+				(struct drm_via_private *)dev->dev_private;
+	struct drm_via_blitq *blitq;
 
 	pci_set_master(dev->pdev);
 
-	for (i=0; i< VIA_NUM_BLIT_ENGINES; ++i) {
+	for (i = 0; i < VIA_NUM_BLIT_ENGINES; ++i) {
 		blitq = dev_priv->blit_queues + i;
 		blitq->dev = dev;
 		blitq->cur_blit_handle = 0;
@@ -565,9 +598,9 @@ via_init_dmablit(struct drm_device *dev)
 		blitq->is_active = 0;
 		blitq->aborting = 0;
 		spin_lock_init(&blitq->blit_lock);
-		for (j=0; j<VIA_NUM_BLIT_SLOTS; ++j) {
+		for (j = 0; j < VIA_NUM_BLIT_SLOTS; ++j)
 			DRM_INIT_WAITQUEUE(blitq->blit_queue + j);
-		}
+
 		DRM_INIT_WAITQUEUE(&blitq->busy_queue);
 		INIT_WORK(&blitq->wq, via_dmablit_workqueue);
 		setup_timer(&blitq->poll_timer, via_dmablit_timer,
@@ -581,7 +614,8 @@ via_init_dmablit(struct drm_device *dev)
 
 
 static int
-via_build_sg_info(struct drm_device *dev, drm_via_sg_info_t *vsg, drm_via_dmablit_t *xfer)
+via_build_sg_info(struct drm_device *dev, struct drm_via_sg_info *vsg,
+		  struct drm_via_dmablit *xfer)
 {
 	int draw = xfer->to_fb;
 	int ret = 0;
@@ -622,7 +656,8 @@ via_build_sg_info(struct drm_device *dev
 	 * DOS security hole.
 	 */
 
-	if (xfer->num_lines > 2048 || (xfer->num_lines*xfer->mem_stride > (2048*2048*4))) {
+	if (xfer->num_lines > 2048 ||
+	   (xfer->num_lines*xfer->mem_stride > (2048*2048*4))) {
 		DRM_ERROR("Too large PCI DMA bitblt.\n");
 		return -EINVAL;
 	}
@@ -639,14 +674,17 @@ via_build_sg_info(struct drm_device *dev
 	}
 
 	/*
-	 * A hardware bug seems to be worked around if system memory addresses start on
-	 * 16 byte boundaries. This seems a bit restrictive however. VIA is contacted
-	 * about this. Meanwhile, impose the following restrictions:
+	 * A hardware bug seems to be worked around if system memory
+	 * addresses start on 16 byte boundaries. This seems a bit
+	 * restrictive however. VIA is contacted about this.
+	 * Meanwhile, impose the following restrictions:
 	 */
 
 #ifdef VIA_BUGFREE
-	if ((((unsigned long)xfer->mem_addr & 3) != ((unsigned long)xfer->fb_addr & 3)) ||
-	    ((xfer->num_lines > 1) && ((xfer->mem_stride & 3) != (xfer->fb_stride & 3)))) {
+	if ((((unsigned long)xfer->mem_addr & 3) !=
+		((unsigned long)xfer->fb_addr & 3)) ||
+	    ((xfer->num_lines > 1) && ((xfer->mem_stride & 3) !=
+	    (xfer->fb_stride & 3)))) {
 		DRM_ERROR("Invalid DRM bitblt alignment.\n");
 		return -EINVAL;
 	}
@@ -654,20 +692,21 @@ via_build_sg_info(struct drm_device *dev
 	if ((((unsigned long)xfer->mem_addr & 15) ||
 	      ((unsigned long)xfer->fb_addr & 3)) ||
 	   ((xfer->num_lines > 1) &&
-	   ((xfer->mem_stride & 15) || (xfer->fb_stride & 3)))) {
+		((xfer->mem_stride & 15) || (xfer->fb_stride & 3)))) {
 		DRM_ERROR("Invalid DRM bitblt alignment.\n");
 		return -EINVAL;
 	}
 #endif
-
-	if (0 != (ret = via_lock_all_dma_pages(vsg, xfer))) {
+	ret = via_lock_all_dma_pages(vsg, xfer);
+	if (0 != ret) {
 		DRM_ERROR("Could not lock DMA pages.\n");
 		via_free_sg_info(dev->pdev, vsg);
 		return ret;
 	}
 
 	via_map_blit_for_device(dev->pdev, xfer, vsg, 0);
-	if (0 != (ret = via_alloc_desc_pages(vsg))) {
+	ret = via_alloc_desc_pages(vsg);
+	if (0 != ret) {
 		DRM_ERROR("Could not allocate DMA descriptor pages.\n");
 		via_free_sg_info(dev->pdev, vsg);
 		return ret;
@@ -684,20 +723,21 @@ via_build_sg_info(struct drm_device *dev
  */
 
 static int
-via_dmablit_grab_slot(drm_via_blitq_t *blitq, int engine)
+via_dmablit_grab_slot(struct drm_via_blitq *blitq, int engine)
 {
-	int ret=0;
+	int ret = 0;
 	unsigned long irqsave;
 
 	DRM_DEBUG("Num free is %d\n", blitq->num_free);
 	spin_lock_irqsave(&blitq->blit_lock, irqsave);
+	while (blitq->num_free == 0) {
 	while(blitq->num_free == 0) {
 		spin_unlock_irqrestore(&blitq->blit_lock, irqsave);
 
-		DRM_WAIT_ON(ret, blitq->busy_queue, DRM_HZ, blitq->num_free > 0);
-		if (ret) {
+		DRM_WAIT_ON(ret, blitq->busy_queue, DRM_HZ,
+			blitq->num_free > 0);
+		if (ret)
 			return (-EINTR == ret) ? -EAGAIN : ret;
-		}
 
 		spin_lock_irqsave(&blitq->blit_lock, irqsave);
 	}
@@ -713,14 +753,14 @@ via_dmablit_grab_slot(drm_via_blitq_t *b
  */
 
 static void
-via_dmablit_release_slot(drm_via_blitq_t *blitq)
+via_dmablit_release_slot(struct drm_via_blitq *blitq)
 {
 	unsigned long irqsave;
 
 	spin_lock_irqsave(&blitq->blit_lock, irqsave);
 	blitq->num_free++;
 	spin_unlock_irqrestore(&blitq->blit_lock, irqsave);
-	DRM_WAKEUP( &blitq->busy_queue );
+	DRM_WAKEUP(&blitq->busy_queue);
 }
 
 /*
@@ -729,11 +769,12 @@ via_dmablit_release_slot(drm_via_blitq_t
 
 
 static int
-via_dmablit(struct drm_device *dev, drm_via_dmablit_t *xfer)
+via_dmablit(struct drm_device *dev, struct drm_via_dmablit *xfer)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;
-	drm_via_sg_info_t *vsg;
-	drm_via_blitq_t *blitq;
+	struct drm_via_private *dev_priv =
+			(struct drm_via_private *)dev->dev_private;
+	struct drm_via_sg_info *vsg;
+	struct drm_via_blitq *blitq;
 	int ret;
 	int engine;
 	unsigned long irqsave;
@@ -745,14 +786,16 @@ via_dmablit(struct drm_device *dev, drm_
 
 	engine = (xfer->to_fb) ? 0 : 1;
 	blitq = dev_priv->blit_queues + engine;
-	if (0 != (ret = via_dmablit_grab_slot(blitq, engine))) {
+	ret = via_dmablit_grab_slot(blitq, engine);
+	if (0 != ret)
 		return ret;
-	}
-	if (NULL == (vsg = kmalloc(sizeof(*vsg), GFP_KERNEL))) {
+	vsg = kmalloc(sizeof(*vsg), GFP_KERNEL);
+	if (NULL == vsg) {
 		via_dmablit_release_slot(blitq);
 		return -ENOMEM;
 	}
-	if (0 != (ret = via_build_sg_info(dev, vsg, xfer))) {
+	ret = via_build_sg_info(dev, vsg, xfer);
+	if (0 != ret) {
 		via_dmablit_release_slot(blitq);
 		kfree(vsg);
 		return ret;
@@ -774,16 +817,19 @@ via_dmablit(struct drm_device *dev, drm_
 }
 
 /*
- * Sync on a previously submitted blit. Note that the X server use signals extensively, and
- * that there is a very big probability that this IOCTL will be interrupted by a signal. In that
- * case it returns with -EAGAIN for the signal to be delivered.
- * The caller should then reissue the IOCTL. This is similar to what is being done for drmGetLock().
+ * Sync on a previously submitted blit. Note that the X
+ * server use signals extensively, and that there is a very
+ * big probability that this IOCTL will be interrupted by a signal.
+ * In that case it returns with -EAGAIN for the signal to be delivered.
+ * The caller should then reissue the IOCTL. This is similar to
+ * what is being done for drmGetLock().
  */
 
 int
-via_dma_blit_sync( struct drm_device *dev, void *data, struct drm_file *file_priv )
+via_dma_blit_sync(struct drm_device *dev, void *data,
+		  struct drm_file *file_priv)
 {
-	drm_via_blitsync_t *sync = data;
+	struct drm_via_blitsync *sync = data;
 	int err;
 
 	if (sync->engine >= VIA_NUM_BLIT_ENGINES)
@@ -799,15 +845,16 @@ via_dma_blit_sync( struct drm_device *de
 
 
 /*
- * Queue a blit and hand back a handle to be used for sync. This IOCTL may be interrupted by a signal
- * while waiting for a free slot in the blit queue. In that case it returns with -EAGAIN and should
- * be reissued. See the above IOCTL code.
+ * Queue a blit and hand back a handle to be used for sync.
+ * This IOCTL may be interrupted by a signal while waiting for
+ * a free slot in the blit queue. In that case it returns with
+ * -EAGAIN and should be reissued. See the above IOCTL code.
  */
 
 int
-via_dma_blit( struct drm_device *dev, void *data, struct drm_file *file_priv )
+via_dma_blit(struct drm_device *dev, void *data, struct drm_file *file_priv)
 {
-	drm_via_dmablit_t *xfer = data;
+	struct drm_via_dmablit *xfer = data;
 	int err;
 
 	err = via_dmablit(dev, xfer);
--- a/drivers/char/drm/via_dmablit.h
+++ b/drivers/char/drm/via_dmablit.h
@@ -35,30 +35,30 @@
 #define VIA_NUM_BLIT_ENGINES 2
 #define VIA_NUM_BLIT_SLOTS 8
 
-struct _drm_via_descriptor;
+struct drm_via_descriptor;
 
-typedef struct _drm_via_sg_info {
+struct drm_via_sg_info {
 	struct page **pages;
 	unsigned long num_pages;
-	struct _drm_via_descriptor **desc_pages;
+	struct drm_via_descriptor **desc_pages;
 	int num_desc_pages;
 	int num_desc;
 	enum dma_data_direction direction;
 	unsigned char *bounce_buffer;
-        dma_addr_t chain_start;
+	dma_addr_t chain_start;
 	uint32_t free_on_sequence;
-        unsigned int descriptors_per_page;
+	unsigned int descriptors_per_page;
 	int aborted;
 	enum {
-	        dr_via_device_mapped,
+		dr_via_device_mapped,
 		dr_via_desc_pages_alloc,
 		dr_via_pages_locked,
 		dr_via_pages_alloc,
 		dr_via_sg_init
 	} state;
-} drm_via_sg_info_t;
+};
 
-typedef struct _drm_via_blitq {
+struct drm_via_blitq {
 	struct drm_device *dev;
 	uint32_t cur_blit_handle;
 	uint32_t done_blit_handle;
@@ -68,15 +68,15 @@ typedef struct _drm_via_blitq {
 	unsigned num_free;
 	unsigned num_outstanding;
 	unsigned long end;
-        int aborting;
+	int aborting;
 	int is_active;
-	drm_via_sg_info_t *blits[VIA_NUM_BLIT_SLOTS];
+	struct drm_via_sg_info *blits[VIA_NUM_BLIT_SLOTS];
 	spinlock_t blit_lock;
 	wait_queue_head_t blit_queue[VIA_NUM_BLIT_SLOTS];
 	wait_queue_head_t busy_queue;
 	struct work_struct wq;
 	struct timer_list poll_timer;
-} drm_via_blitq_t;
+};
 
 
 /*
--- a/drivers/char/drm/via_dma.c
+++ b/drivers/char/drm/via_dma.c
@@ -58,28 +58,31 @@
 	*((uint32_t *)(vb)) = ((nReg) >> 2) | HALCYON_HEADER1;	\
 	*((uint32_t *)(vb) + 1) = (nData);			\
 	vb = ((uint32_t *)vb) + 2;				\
-	dev_priv->dma_low +=8;					\
+	dev_priv->dma_low += 8;					\
 }
 
 #define via_flush_write_combine() DRM_MEMORYBARRIER()
 
 #define VIA_OUT_RING_QW(w1,w2)			\
+	do {					\
 	*vb++ = (w1);				\
 	*vb++ = (w2);				\
-	dev_priv->dma_low += 8;
+	dev_priv->dma_low += 8;			\
+	} while (0);
+
+static void via_cmdbuf_start(struct drm_via_private *dev_priv);
+static void via_cmdbuf_pause(struct drm_via_private *dev_priv);
+static void via_cmdbuf_reset(struct drm_via_private *dev_priv);
+static void via_cmdbuf_rewind(struct drm_via_private *dev_priv);
+static int via_wait_idle(struct drm_via_private *dev_priv);
+static void via_pad_cache(struct drm_via_private *dev_priv, int qwords);
 
-static void via_cmdbuf_start(drm_via_private_t * dev_priv);
-static void via_cmdbuf_pause(drm_via_private_t * dev_priv);
-static void via_cmdbuf_reset(drm_via_private_t * dev_priv);
-static void via_cmdbuf_rewind(drm_via_private_t * dev_priv);
-static int via_wait_idle(drm_via_private_t * dev_priv);
-static void via_pad_cache(drm_via_private_t * dev_priv, int qwords);
 
 /*
  * Free space in command buffer.
  */
 
-static uint32_t via_cmdbuf_space(drm_via_private_t * dev_priv)
+static uint32_t via_cmdbuf_space(struct drm_via_private *dev_priv)
 {
 	uint32_t agp_base = dev_priv->dma_offset + (uint32_t) dev_priv->agpAddr;
 	uint32_t hw_addr = *(dev_priv->hw_addr_ptr) - agp_base;
@@ -93,7 +96,7 @@ static uint32_t via_cmdbuf_space(drm_via
  * How much does the command regulator lag behind?
  */
 
-static uint32_t via_cmdbuf_lag(drm_via_private_t * dev_priv)
+static uint32_t via_cmdbuf_lag(struct drm_via_private *dev_priv)
 {
 	uint32_t agp_base = dev_priv->dma_offset + (uint32_t) dev_priv->agpAddr;
 	uint32_t hw_addr = *(dev_priv->hw_addr_ptr) - agp_base;
@@ -108,7 +111,7 @@ static uint32_t via_cmdbuf_lag(drm_via_p
  */
 
 static inline int
-via_cmdbuf_wait(drm_via_private_t * dev_priv, unsigned int size)
+via_cmdbuf_wait(struct drm_via_private *dev_priv, unsigned int size)
 {
 	uint32_t agp_base = dev_priv->dma_offset + (uint32_t) dev_priv->agpAddr;
 	uint32_t cur_addr, hw_addr, next_addr;
@@ -122,7 +125,7 @@ via_cmdbuf_wait(drm_via_private_t * dev_
 		hw_addr = *hw_addr_ptr - agp_base;
 		if (count-- == 0) {
 			DRM_ERROR
-			    ("via_cmdbuf_wait timed out hw %x cur_addr %x next_addr %x\n",
+		("via_cmdbuf_wait timed out hw %x cur_addr %x next_addr %x\n",
 			     hw_addr, cur_addr, next_addr);
 			return -1;
 		}
@@ -139,25 +142,25 @@ via_cmdbuf_wait(drm_via_private_t * dev_
  * Returns virtual pointer to ring buffer.
  */
 
-static inline uint32_t *via_check_dma(drm_via_private_t * dev_priv,
+static inline uint32_t *via_check_dma(struct drm_via_private *dev_priv,
 				      unsigned int size)
 {
 	if ((dev_priv->dma_low + size + 4 * CMDBUF_ALIGNMENT_SIZE) >
-	    dev_priv->dma_high) {
+	    dev_priv->dma_high)
 		via_cmdbuf_rewind(dev_priv);
-	}
-	if (via_cmdbuf_wait(dev_priv, size) != 0) {
+
+	if (via_cmdbuf_wait(dev_priv, size) != 0)
 		return NULL;
-	}
+
 
 	return (uint32_t *) (dev_priv->dma_ptr + dev_priv->dma_low);
 }
 
-int via_dma_cleanup(struct drm_device * dev)
+int via_dma_cleanup(struct drm_device *dev)
 {
 	if (dev->dev_private) {
-		drm_via_private_t *dev_priv =
-		    (drm_via_private_t *) dev->dev_private;
+		struct drm_via_private *dev_priv =
+		    (struct drm_via_private *) dev->dev_private;
 
 		if (dev_priv->ring.virtual_start) {
 			via_cmdbuf_reset(dev_priv);
@@ -171,9 +174,9 @@ int via_dma_cleanup(struct drm_device * 
 	return 0;
 }
 
-static int via_initialize(struct drm_device * dev,
-			  drm_via_private_t * dev_priv,
-			  drm_via_dma_init_t * init)
+static int via_initialize(struct drm_device *dev,
+			  struct drm_via_private *dev_priv,
+			  struct drm_via_dma_init *init)
 {
 	if (!dev_priv || !dev_priv->mmio) {
 		DRM_ERROR("via_dma_init called before via_map_init\n");
@@ -227,10 +230,12 @@ static int via_initialize(struct drm_dev
 	return 0;
 }
 
-static int via_dma_init(struct drm_device *dev, void *data, struct drm_file *file_priv)
+static int via_dma_init(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
-	drm_via_dma_init_t *init = data;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
+	struct drm_via_dma_init *init = data;
 	int retcode = 0;
 
 	switch (init->func) {
@@ -258,44 +263,26 @@ static int via_dma_init(struct drm_devic
 	return retcode;
 }
 
-static int via_dispatch_cmdbuffer(struct drm_device * dev, drm_via_cmdbuffer_t * cmd)
+static int via_dispatch_cmdbuffer(struct drm_device *dev,
+	struct drm_via_cmdbuffer *cmd)
 {
-	drm_via_private_t *dev_priv;
+	struct drm_via_private *dev_priv;
 	uint32_t *vb;
-	int ret;
 
-	dev_priv = (drm_via_private_t *) dev->dev_private;
+	dev_priv = (struct drm_via_private *) dev->dev_private;
 
 	if (dev_priv->ring.virtual_start == NULL) {
 		DRM_ERROR("called without initializing AGP ring buffer.\n");
 		return -EFAULT;
 	}
 
-	if (cmd->size > VIA_PCI_BUF_SIZE) {
-		return -ENOMEM;
-	}
-
-	if (DRM_COPY_FROM_USER(dev_priv->pci_buf, cmd->buf, cmd->size))
-		return -EFAULT;
-
-	/*
-	 * Running this function on AGP memory is dead slow. Therefore
-	 * we run it on a temporary cacheable system memory buffer and
-	 * copy it to AGP memory when ready.
-	 */
-
-	if ((ret =
-	     via_verify_command_stream((uint32_t *) dev_priv->pci_buf,
-				       cmd->size, dev, 1))) {
-		return ret;
-	}
-
 	vb = via_check_dma(dev_priv, (cmd->size < 0x100) ? 0x102 : cmd->size);
-	if (vb == NULL) {
+	if (vb == NULL)
 		return -EAGAIN;
-	}
 
-	memcpy(vb, dev_priv->pci_buf, cmd->size);
+
+	if (DRM_COPY_FROM_USER(vb, cmd->buf, cmd->size))
+		return -EFAULT;
 
 	dev_priv->dma_low += cmd->size;
 
@@ -311,17 +298,18 @@ static int via_dispatch_cmdbuffer(struct
 	return 0;
 }
 
-int via_driver_dma_quiescent(struct drm_device * dev)
+int via_driver_dma_quiescent(struct drm_device *dev)
 {
-	drm_via_private_t *dev_priv = dev->dev_private;
+	struct drm_via_private *dev_priv = dev->dev_private;
 
-	if (!via_wait_idle(dev_priv)) {
+	if (!via_wait_idle(dev_priv))
 		return -EBUSY;
-	}
+
 	return 0;
 }
 
-static int via_flush_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv)
+static int via_flush_ioctl(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
 
 	LOCK_TEST_WITH_RETURN(dev, file_priv);
@@ -329,9 +317,10 @@ static int via_flush_ioctl(struct drm_de
 	return via_driver_dma_quiescent(dev);
 }
 
-static int via_cmdbuffer(struct drm_device *dev, void *data, struct drm_file *file_priv)
+static int via_cmdbuffer(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
-	drm_via_cmdbuffer_t *cmdbuf = data;
+	struct drm_via_cmdbuffer *cmdbuf = data;
 	int ret;
 
 	LOCK_TEST_WITH_RETURN(dev, file_priv);
@@ -339,30 +328,31 @@ static int via_cmdbuffer(struct drm_devi
 	DRM_DEBUG("buf %p size %lu\n", cmdbuf->buf, cmdbuf->size);
 
 	ret = via_dispatch_cmdbuffer(dev, cmdbuf);
-	if (ret) {
+	if (ret)
 		return ret;
-	}
+
 
 	return 0;
 }
 
-static int via_dispatch_pci_cmdbuffer(struct drm_device * dev,
-				      drm_via_cmdbuffer_t * cmd)
+static int via_dispatch_pci_cmdbuffer(struct drm_device *dev,
+				      struct drm_via_cmdbuffer *cmd)
 {
-	drm_via_private_t *dev_priv = dev->dev_private;
+	struct drm_via_private *dev_priv = dev->dev_private;
 	int ret;
 
-	if (cmd->size > VIA_PCI_BUF_SIZE) {
+	if (cmd->size > VIA_PCI_BUF_SIZE)
 		return -ENOMEM;
-	}
+
 	if (DRM_COPY_FROM_USER(dev_priv->pci_buf, cmd->buf, cmd->size))
 		return -EFAULT;
-
-	if ((ret =
+	ret =
 	     via_verify_command_stream((uint32_t *) dev_priv->pci_buf,
-				       cmd->size, dev, 0))) {
+				       cmd->size, dev, 0);
+
+	if (ret)
 		return ret;
-	}
+
 
 	ret =
 	    via_parse_command_stream(dev, (const uint32_t *)dev_priv->pci_buf,
@@ -370,9 +360,10 @@ static int via_dispatch_pci_cmdbuffer(st
 	return ret;
 }
 
-static int via_pci_cmdbuffer(struct drm_device *dev, void *data, struct drm_file *file_priv)
+static int via_pci_cmdbuffer(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
-	drm_via_cmdbuffer_t *cmdbuf = data;
+	struct drm_via_cmdbuffer *cmdbuf = data;
 	int ret;
 
 	LOCK_TEST_WITH_RETURN(dev, file_priv);
@@ -380,19 +371,19 @@ static int via_pci_cmdbuffer(struct drm_
 	DRM_DEBUG("buf %p size %lu\n", cmdbuf->buf, cmdbuf->size);
 
 	ret = via_dispatch_pci_cmdbuffer(dev, cmdbuf);
-	if (ret) {
+	if (ret)
 		return ret;
-	}
+
 
 	return 0;
 }
 
-static inline uint32_t *via_align_buffer(drm_via_private_t * dev_priv,
-					 uint32_t * vb, int qw_count)
+static inline uint32_t *via_align_buffer(struct drm_via_private *dev_priv,
+					 uint32_t *vb, int qw_count)
 {
-	for (; qw_count > 0; --qw_count) {
+	for (; qw_count > 0; --qw_count)
 		VIA_OUT_RING_QW(HC_DUMMY, HC_DUMMY);
-	}
+
 	return vb;
 }
 
@@ -401,7 +392,7 @@ static inline uint32_t *via_align_buffer
  *
  * Returns virtual pointer to ring buffer.
  */
-static inline uint32_t *via_get_dma(drm_via_private_t * dev_priv)
+static inline uint32_t *via_get_dma(struct drm_via_private *dev_priv)
 {
 	return (uint32_t *) (dev_priv->dma_ptr + dev_priv->dma_low);
 }
@@ -411,18 +402,18 @@ static inline uint32_t *via_get_dma(drm_
  * modifying the pause address stored in the buffer itself. If
  * the regulator has already paused, restart it.
  */
-static int via_hook_segment(drm_via_private_t * dev_priv,
+static int via_hook_segment(struct drm_via_private *dev_priv,
 			    uint32_t pause_addr_hi, uint32_t pause_addr_lo,
 			    int no_pci_fire)
 {
 	int paused, count;
 	volatile uint32_t *paused_at = dev_priv->last_pause_ptr;
-	uint32_t reader,ptr;
+	uint32_t reader, ptr;
 	uint32_t diff;
 
 	paused = 0;
 	via_flush_write_combine();
-	(void) *(volatile uint32_t *)(via_get_dma(dev_priv) -1);
+	(void) *(volatile uint32_t *)(via_get_dma(dev_priv) - 1);
 
 	*paused_at = pause_addr_lo;
 	via_flush_write_combine();
@@ -443,7 +434,7 @@ static int via_hook_segment(drm_via_priv
 
 	diff = (uint32_t) (ptr - reader) - dev_priv->dma_diff;
 	count = 10000000;
-	while(diff == 0 && count--) {
+	while (diff == 0 && count--) {
 		paused = (VIA_READ(0x41c) & 0x80000000);
 		if (paused) 
 			break;
@@ -463,9 +454,9 @@ static int via_hook_segment(drm_via_priv
 				  ptr, reader, dev_priv->dma_diff);
 		} else if (diff == 0) {
 			/*
-			 * There is a concern that these writes may stall the PCI bus
-			 * if the GPU is not idle. However, idling the GPU first
-			 * doesn't make a difference.
+			 * There is a concern that these writes may stall
+			 * the PCI bus if the GPU is not idle. However,
+			 * idling the GPU first doesn't make a difference.
 			 */
 
 			VIA_WRITE(VIA_REG_TRANSET, (HC_ParaType_PreCR << 16));
@@ -477,7 +468,7 @@ static int via_hook_segment(drm_via_priv
 	return paused;
 }
 
-static int via_wait_idle(drm_via_private_t * dev_priv)
+static int via_wait_idle(struct drm_via_private *dev_priv)
 {
 	int count = 10000000;
 
@@ -489,9 +480,9 @@ static int via_wait_idle(drm_via_private
 	return count;
 }
 
-static uint32_t *via_align_cmd(drm_via_private_t * dev_priv, uint32_t cmd_type,
-			       uint32_t addr, uint32_t * cmd_addr_hi,
-			       uint32_t * cmd_addr_lo, int skip_wait)
+static uint32_t *via_align_cmd(struct drm_via_private *dev_priv,
+	uint32_t cmd_type, uint32_t addr, uint32_t *cmd_addr_hi,
+	uint32_t *cmd_addr_lo, int skip_wait)
 {
 	uint32_t agp_base;
 	uint32_t cmd_addr, addr_lo, addr_hi;
@@ -519,7 +510,7 @@ static uint32_t *via_align_cmd(drm_via_p
 	return vb;
 }
 
-static void via_cmdbuf_start(drm_via_private_t * dev_priv)
+static void via_cmdbuf_start(struct drm_via_private *dev_priv)
 {
 	uint32_t pause_addr_lo, pause_addr_hi;
 	uint32_t start_addr, start_addr_lo;
@@ -578,7 +569,7 @@ static void via_cmdbuf_start(drm_via_pri
 	dev_priv->dma_diff = ptr - reader;
 }
 
-static void via_pad_cache(drm_via_private_t * dev_priv, int qwords)
+static void via_pad_cache(struct drm_via_private *dev_priv, int qwords)
 {
 	uint32_t *vb;
 
@@ -588,7 +579,7 @@ static void via_pad_cache(drm_via_privat
 	via_align_buffer(dev_priv, vb, qwords);
 }
 
-static inline void via_dummy_bitblt(drm_via_private_t * dev_priv)
+static inline void via_dummy_bitblt(struct drm_via_private *dev_priv)
 {
 	uint32_t *vb = via_get_dma(dev_priv);
 	SetReg2DAGP(0x0C, (0 | (0 << 16)));
@@ -596,7 +587,7 @@ static inline void via_dummy_bitblt(drm_
 	SetReg2DAGP(0x0, 0x1 | 0x2000 | 0xAA000000);
 }
 
-static void via_cmdbuf_jump(drm_via_private_t * dev_priv)
+static void via_cmdbuf_jump(struct drm_via_private *dev_priv)
 {
 	uint32_t agp_base;
 	uint32_t pause_addr_lo, pause_addr_hi;
@@ -615,9 +606,9 @@ static void via_cmdbuf_jump(drm_via_priv
 	 */
 
 	dev_priv->dma_low = 0;
-	if (via_cmdbuf_wait(dev_priv, CMDBUF_ALIGNMENT_SIZE) != 0) {
+	if (via_cmdbuf_wait(dev_priv, CMDBUF_ALIGNMENT_SIZE) != 0)
 		DRM_ERROR("via_cmdbuf_jump failed\n");
-	}
+
 
 	via_dummy_bitblt(dev_priv);
 	via_dummy_bitblt(dev_priv);
@@ -655,12 +646,13 @@ static void via_cmdbuf_jump(drm_via_priv
 }
 
 
-static void via_cmdbuf_rewind(drm_via_private_t * dev_priv)
+static void via_cmdbuf_rewind(struct drm_via_private *dev_priv)
 {
 	via_cmdbuf_jump(dev_priv);
 }
 
-static void via_cmdbuf_flush(drm_via_private_t * dev_priv, uint32_t cmd_type)
+static void via_cmdbuf_flush(struct drm_via_private *dev_priv,
+			     uint32_t cmd_type)
 {
 	uint32_t pause_addr_lo, pause_addr_hi;
 
@@ -668,12 +660,12 @@ static void via_cmdbuf_flush(drm_via_pri
 	via_hook_segment(dev_priv, pause_addr_hi, pause_addr_lo, 0);
 }
 
-static void via_cmdbuf_pause(drm_via_private_t * dev_priv)
+static void via_cmdbuf_pause(struct drm_via_private *dev_priv)
 {
 	via_cmdbuf_flush(dev_priv, HC_HAGPBpID_PAUSE);
 }
 
-static void via_cmdbuf_reset(drm_via_private_t * dev_priv)
+static void via_cmdbuf_reset(struct drm_via_private *dev_priv)
 {
 	via_cmdbuf_flush(dev_priv, HC_HAGPBpID_STOP);
 	via_wait_idle(dev_priv);
@@ -683,17 +675,18 @@ static void via_cmdbuf_reset(drm_via_pri
  * User interface to the space and lag functions.
  */
 
-static int via_cmdbuf_size(struct drm_device *dev, void *data, struct drm_file *file_priv)
+static int via_cmdbuf_size(struct drm_device *dev, void *data,
+			   struct drm_file *file_priv)
 {
-	drm_via_cmdbuf_size_t *d_siz = data;
+	struct drm_via_cmdbuf_size *d_siz = data;
 	int ret = 0;
 	uint32_t tmp_size, count;
-	drm_via_private_t *dev_priv;
+	struct drm_via_private *dev_priv;
 
-	DRM_DEBUG("\n");
+	DRM_DEBUG("via cmdbuf_size\n");
 	LOCK_TEST_WITH_RETURN(dev, file_priv);
 
-	dev_priv = (drm_via_private_t *) dev->dev_private;
+	dev_priv = (struct drm_via_private *) dev->dev_private;
 
 	if (dev_priv->ring.virtual_start == NULL) {
 		DRM_ERROR("called without initializing AGP ring buffer.\n");
@@ -706,9 +699,9 @@ static int via_cmdbuf_size(struct drm_de
 	case VIA_CMDBUF_SPACE:
 		while (((tmp_size = via_cmdbuf_space(dev_priv)) < d_siz->size)
 		       && count--) {
-			if (!d_siz->wait) {
+			if (!d_siz->wait)
 				break;
-			}
+
 		}
 		if (!count) {
 			DRM_ERROR("VIA_CMDBUF_SPACE timed out.\n");
@@ -718,9 +711,9 @@ static int via_cmdbuf_size(struct drm_de
 	case VIA_CMDBUF_LAG:
 		while (((tmp_size = via_cmdbuf_lag(dev_priv)) > d_siz->size)
 		       && count--) {
-			if (!d_siz->wait) {
+			if (!d_siz->wait)
 				break;
-			}
+
 		}
 		if (!count) {
 			DRM_ERROR("VIA_CMDBUF_LAG timed out.\n");
@@ -735,6 +728,144 @@ static int via_cmdbuf_size(struct drm_de
 	return ret;
 }
 
+/*The following functions are for ACPI*/
+
+static void initialize3Dengine(struct drm_via_private *dev_priv)
+{
+	int i = 0;
+
+	VIA_WRITE(0x43C, 0x00010000);
+
+	for (i = 0; i <= 0x7D; i++)
+		VIA_WRITE(0x440, (unsigned long) i << 24);
+
+
+	VIA_WRITE(0x43C, 0x00020000);
+
+	for (i = 0; i <= 0x94; i++)
+		VIA_WRITE(0x440, (unsigned long) i << 24);
+
+
+	VIA_WRITE(0x440, 0x82400000);
+	VIA_WRITE(0x43C, 0x01020000);
+
+
+	for (i = 0; i <= 0x94; i++)
+		VIA_WRITE(0x440, (unsigned long) i << 24);
+
+
+	VIA_WRITE(0x440, 0x82400000);
+	VIA_WRITE(0x43C, 0xfe020000);
+
+	for (i = 0; i <= 0x03; i++)
+		VIA_WRITE(0x440, (unsigned long) i << 24);
+
+
+	VIA_WRITE(0x43C, 0x00030000);
+
+	for (i = 0; i <= 0xff; i++)
+		VIA_WRITE(0x440, 0);
+
+	VIA_WRITE(0x43C, 0x00100000);
+	VIA_WRITE(0x440, 0x00333004);
+	VIA_WRITE(0x440, 0x10000002);
+	VIA_WRITE(0x440, 0x60000000);
+	VIA_WRITE(0x440, 0x61000000);
+	VIA_WRITE(0x440, 0x62000000);
+	VIA_WRITE(0x440, 0x63000000);
+	VIA_WRITE(0x440, 0x64000000);
+
+	VIA_WRITE(0x43C, 0x00fe0000);
+	VIA_WRITE(0x440, 0x40008c0f);
+	VIA_WRITE(0x440, 0x44000000);
+	VIA_WRITE(0x440, 0x45080C04);
+	VIA_WRITE(0x440, 0x46800408);
+	VIA_WRITE(0x440, 0x50000000);
+	VIA_WRITE(0x440, 0x51000000);
+	VIA_WRITE(0x440, 0x52000000);
+	VIA_WRITE(0x440, 0x53000000);
+
+
+	VIA_WRITE(0x43C, 0x00fe0000);
+	VIA_WRITE(0x440, 0x08000001);
+	VIA_WRITE(0x440, 0x0A000183);
+	VIA_WRITE(0x440, 0x0B00019F);
+	VIA_WRITE(0x440, 0x0C00018B);
+	VIA_WRITE(0x440, 0x0D00019B);
+	VIA_WRITE(0x440, 0x0E000000);
+	VIA_WRITE(0x440, 0x0F000000);
+	VIA_WRITE(0x440, 0x10000000);
+	VIA_WRITE(0x440, 0x11000000);
+	VIA_WRITE(0x440, 0x20000000);
+}
+
+
+/* For acpi case, when system resume from suspend or hibernate,
+ * need to re-initialize dma info into HW
+ */
+int via_drm_resume(struct pci_dev *pci)
+{
+	struct drm_device *dev = (struct drm_device *)pci_get_drvdata(pci);
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
+	struct drm_via_video_save_head *pnode = 0;
+
+    /* when resume, initialize 3d registers */
+	initialize3Dengine(dev_priv);
+
+    /* here we need to restore some video memory content */
+	for (pnode = via_video_save_head; pnode; pnode = pnode->next)
+		memcpy(pnode->pvideomem, pnode->psystemmem, pnode->size);
+
+
+    /* if pci path, return */
+	if (!dev_priv->ring.virtual_start)
+		return 0;
+
+	dev_priv->dma_ptr = dev_priv->ring.virtual_start;
+	dev_priv->dma_low = 0;
+	dev_priv->dma_high = 0x1000000;
+	dev_priv->dma_wrap = 0x1000000;
+	dev_priv->dma_offset = 0x0;
+	dev_priv->last_pause_ptr = NULL;
+	dev_priv->hw_addr_ptr = dev_priv->mmio->handle + 0x418;
+
+	via_cmdbuf_start(dev_priv);
+
+	return 0;
+}
+
+int via_drm_suspend(struct pci_dev *pci, pm_message_t state)
+{
+	struct drm_device *dev = (struct drm_device *)pci_get_drvdata(pci);
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
+
+	struct drm_via_video_save_head *pnode = 0;
+
+    /*here we need to save some video mem information into system memory,
+     to keep the system consistent between suspend *before* and *after*
+     1.save only necessary */
+	for (pnode = via_video_save_head; pnode; pnode =
+		(struct drm_via_video_save_head *)pnode->next)
+		memcpy(pnode->psystemmem, pnode->pvideomem, pnode->size);
+
+
+    /* Only agp path need to flush the cmd */
+	if (dev_priv->ring.virtual_start)
+		via_cmdbuf_reset(dev_priv);
+
+
+	return 0;
+}
+
+int via_drm_authmagic(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
+{
+	return 0;
+}
+
+
 struct drm_ioctl_desc via_ioctls[] = {
 	DRM_IOCTL_DEF(DRM_VIA_ALLOCMEM, via_mem_alloc, DRM_AUTH),
 	DRM_IOCTL_DEF(DRM_VIA_FREEMEM, via_mem_free, DRM_AUTH),
@@ -742,6 +873,7 @@ struct drm_ioctl_desc via_ioctls[] = {
 	DRM_IOCTL_DEF(DRM_VIA_FB_INIT, via_fb_init, DRM_AUTH|DRM_MASTER),
 	DRM_IOCTL_DEF(DRM_VIA_MAP_INIT, via_map_init, DRM_AUTH|DRM_MASTER),
 	DRM_IOCTL_DEF(DRM_VIA_DEC_FUTEX, via_decoder_futex, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_VIA_GET_INFO, via_get_drm_info, DRM_AUTH),
 	DRM_IOCTL_DEF(DRM_VIA_DMA_INIT, via_dma_init, DRM_AUTH),
 	DRM_IOCTL_DEF(DRM_VIA_CMDBUFFER, via_cmdbuffer, DRM_AUTH),
 	DRM_IOCTL_DEF(DRM_VIA_FLUSH, via_flush_ioctl, DRM_AUTH),
@@ -749,7 +881,8 @@ struct drm_ioctl_desc via_ioctls[] = {
 	DRM_IOCTL_DEF(DRM_VIA_CMDBUF_SIZE, via_cmdbuf_size, DRM_AUTH),
 	DRM_IOCTL_DEF(DRM_VIA_WAIT_IRQ, via_wait_irq, DRM_AUTH),
 	DRM_IOCTL_DEF(DRM_VIA_DMA_BLIT, via_dma_blit, DRM_AUTH),
-	DRM_IOCTL_DEF(DRM_VIA_BLIT_SYNC, via_dma_blit_sync, DRM_AUTH)
+	DRM_IOCTL_DEF(DRM_VIA_BLIT_SYNC, via_dma_blit_sync, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_VIA_AUTH_MAGIC, via_drm_authmagic, 0)
 };
 
 int via_max_ioctl = DRM_ARRAY_SIZE(via_ioctls);
--- a/drivers/char/drm/via_drm.h
+++ b/drivers/char/drm/via_drm.h
@@ -40,7 +40,8 @@
 #define VIA_NR_XVMC_LOCKS               5
 #define VIA_MAX_CACHELINE_SIZE          64
 #define XVMCLOCKPTR(saPriv,lockNo)					\
-	((volatile struct drm_hw_lock *)(((((unsigned long) (saPriv)->XvMCLockArea) + \
+	((volatile struct drm_hw_lock *)(((((unsigned long)         \
+					(saPriv)->XvMCLockArea) + 	\
 				      (VIA_MAX_CACHELINE_SIZE - 1)) &	\
 				     ~(VIA_MAX_CACHELINE_SIZE - 1)) +	\
 				    VIA_MAX_CACHELINE_SIZE*(lockNo)))
@@ -51,6 +52,13 @@
 #define VIA_LOG_MIN_TEX_REGION_SIZE 16
 #endif
 
+struct drm_via_info{
+	unsigned long AgpHandle;
+	unsigned long AgpSize;
+	unsigned long RegHandle;
+	unsigned long RegSize;
+};
+
 #define VIA_UPLOAD_TEX0IMAGE  0x1	/* handled clientside */
 #define VIA_UPLOAD_TEX1IMAGE  0x2	/* handled clientside */
 #define VIA_UPLOAD_CTX        0x4
@@ -67,7 +75,7 @@
 #define DRM_VIA_FB_INIT	        0x03
 #define DRM_VIA_MAP_INIT	0x04
 #define DRM_VIA_DEC_FUTEX       0x05
-#define NOT_USED
+#define DRM_VIA_GET_INFO    0x06
 #define DRM_VIA_DMA_INIT	0x07
 #define DRM_VIA_CMDBUFFER	0x08
 #define DRM_VIA_FLUSH	        0x09
@@ -77,22 +85,39 @@
 #define DRM_VIA_WAIT_IRQ        0x0d
 #define DRM_VIA_DMA_BLIT        0x0e
 #define DRM_VIA_BLIT_SYNC       0x0f
+#define DRM_VIA_AUTH_MAGIC      0x11
 
-#define DRM_IOCTL_VIA_ALLOCMEM	  DRM_IOWR(DRM_COMMAND_BASE + DRM_VIA_ALLOCMEM, drm_via_mem_t)
-#define DRM_IOCTL_VIA_FREEMEM	  DRM_IOW( DRM_COMMAND_BASE + DRM_VIA_FREEMEM, drm_via_mem_t)
-#define DRM_IOCTL_VIA_AGP_INIT	  DRM_IOWR(DRM_COMMAND_BASE + DRM_VIA_AGP_INIT, drm_via_agp_t)
-#define DRM_IOCTL_VIA_FB_INIT	  DRM_IOWR(DRM_COMMAND_BASE + DRM_VIA_FB_INIT, drm_via_fb_t)
-#define DRM_IOCTL_VIA_MAP_INIT	  DRM_IOWR(DRM_COMMAND_BASE + DRM_VIA_MAP_INIT, drm_via_init_t)
-#define DRM_IOCTL_VIA_DEC_FUTEX   DRM_IOW( DRM_COMMAND_BASE + DRM_VIA_DEC_FUTEX, drm_via_futex_t)
-#define DRM_IOCTL_VIA_DMA_INIT	  DRM_IOWR(DRM_COMMAND_BASE + DRM_VIA_DMA_INIT, drm_via_dma_init_t)
-#define DRM_IOCTL_VIA_CMDBUFFER	  DRM_IOW( DRM_COMMAND_BASE + DRM_VIA_CMDBUFFER, drm_via_cmdbuffer_t)
-#define DRM_IOCTL_VIA_FLUSH	  DRM_IO(  DRM_COMMAND_BASE + DRM_VIA_FLUSH)
-#define DRM_IOCTL_VIA_PCICMD	  DRM_IOW( DRM_COMMAND_BASE + DRM_VIA_PCICMD, drm_via_cmdbuffer_t)
-#define DRM_IOCTL_VIA_CMDBUF_SIZE DRM_IOWR( DRM_COMMAND_BASE + DRM_VIA_CMDBUF_SIZE, \
-					    drm_via_cmdbuf_size_t)
-#define DRM_IOCTL_VIA_WAIT_IRQ    DRM_IOWR( DRM_COMMAND_BASE + DRM_VIA_WAIT_IRQ, drm_via_irqwait_t)
-#define DRM_IOCTL_VIA_DMA_BLIT    DRM_IOW(DRM_COMMAND_BASE + DRM_VIA_DMA_BLIT, drm_via_dmablit_t)
-#define DRM_IOCTL_VIA_BLIT_SYNC   DRM_IOW(DRM_COMMAND_BASE + DRM_VIA_BLIT_SYNC, drm_via_blitsync_t)
+#define DRM_IOCTL_VIA_ALLOCMEM	  DRM_IOWR(DRM_COMMAND_BASE + \
+				DRM_VIA_ALLOCMEM, struct drm_via_mem)
+#define DRM_IOCTL_VIA_FREEMEM	  DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_FREEMEM, struct drm_via_mem)
+#define DRM_IOCTL_VIA_AGP_INIT	  DRM_IOWR(DRM_COMMAND_BASE + \
+				DRM_VIA_AGP_INIT, struct drm_via_agp)
+#define DRM_IOCTL_VIA_FB_INIT	  DRM_IOWR(DRM_COMMAND_BASE + \
+				DRM_VIA_FB_INIT, struct drm_via_fb)
+#define DRM_IOCTL_VIA_MAP_INIT	  DRM_IOWR(DRM_COMMAND_BASE + \
+				DRM_VIA_MAP_INIT, struct drm_via_init)
+#define DRM_IOCTL_VIA_DEC_FUTEX   DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_DEC_FUTEX, struct drm_via_futex)
+#define DRM_IOCTL_VIA_GET_INFO    DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_GET_INFO, struct drm_via_info)
+#define DRM_IOCTL_VIA_DMA_INIT	  DRM_IOWR(DRM_COMMAND_BASE + \
+				DRM_VIA_DMA_INIT, struct drm_via_dma_init)
+#define DRM_IOCTL_VIA_CMDBUFFER	  DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_CMDBUFFER, struct drm_via_cmdbuffer)
+#define DRM_IOCTL_VIA_FLUSH	  DRM_IO(DRM_COMMAND_BASE + DRM_VIA_FLUSH)
+#define DRM_IOCTL_VIA_PCICMD	  DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_PCICMD, struct drm_via_cmdbuffer)
+#define DRM_IOCTL_VIA_CMDBUF_SIZE DRM_IOWR(DRM_COMMAND_BASE + \
+				DRM_VIA_CMDBUF_SIZE, struct drm_via_cmdbuf_size)
+#define DRM_IOCTL_VIA_WAIT_IRQ    DRM_IOWR(DRM_COMMAND_BASE + \
+				DRM_VIA_WAIT_IRQ, union drm_via_irqwait)
+#define DRM_IOCTL_VIA_DMA_BLIT    DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_DMA_BLIT, struct drm_via_dmablit)
+#define DRM_IOCTL_VIA_BLIT_SYNC   DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_BLIT_SYNC, struct drm_via_blitsync)
+#define DRM_IOCTL_VIA_AUTH_MAGIC  DRM_IOW(DRM_COMMAND_BASE + \
+				DRM_VIA_AUTH_MAGIC, struct drm_auth)
 
 /* Indices into buf.Setup where various bits of state are mirrored per
  * context and per buffer.  These can be fired at the card as a unit,
@@ -113,25 +138,33 @@
 #define VIA_MEM_MIXED   3
 #define VIA_MEM_UNKNOWN 4
 
-typedef struct {
+#define VIA_MEM_VIDEO_SAVE      2 /*For video memory need to be saved in ACPI */
+
+enum drm_agp_type {
+	AGP_RING_BUFFER,
+	AGP_DOUBLE_BUFFER,
+	DISABLED
+};
+
+struct drm_via_agp {
 	uint32_t offset;
 	uint32_t size;
-} drm_via_agp_t;
+};
 
-typedef struct {
+struct drm_via_fb {
 	uint32_t offset;
 	uint32_t size;
-} drm_via_fb_t;
+};
 
-typedef struct {
+struct drm_via_mem {
 	uint32_t context;
 	uint32_t type;
 	uint32_t size;
 	unsigned long index;
 	unsigned long offset;
-} drm_via_mem_t;
+};
 
-typedef struct _drm_via_init {
+struct drm_via_init {
 	enum {
 		VIA_INIT_MAP = 0x01,
 		VIA_CLEANUP_MAP = 0x02
@@ -141,9 +174,11 @@ typedef struct _drm_via_init {
 	unsigned long fb_offset;
 	unsigned long mmio_offset;
 	unsigned long agpAddr;
-} drm_via_init_t;
+    unsigned long agp_offset;
+    enum drm_agp_type agp_type;
+};
 
-typedef struct _drm_via_futex {
+struct drm_via_futex {
 	enum {
 		VIA_FUTEX_WAIT = 0x00,
 		VIA_FUTEX_WAKE = 0X01
@@ -151,9 +186,9 @@ typedef struct _drm_via_futex {
 	uint32_t ms;
 	uint32_t lock;
 	uint32_t val;
-} drm_via_futex_t;
+};
 
-typedef struct _drm_via_dma_init {
+struct drm_via_dma_init {
 	enum {
 		VIA_INIT_DMA = 0x01,
 		VIA_CLEANUP_DMA = 0x02,
@@ -163,27 +198,27 @@ typedef struct _drm_via_dma_init {
 	unsigned long offset;
 	unsigned long size;
 	unsigned long reg_pause_addr;
-} drm_via_dma_init_t;
+};
 
-typedef struct _drm_via_cmdbuffer {
+struct drm_via_cmdbuffer {
 	char __user *buf;
 	unsigned long size;
-} drm_via_cmdbuffer_t;
+};
 
 /* Warning: If you change the SAREA structure you must change the Xserver
  * structure as well */
 
-typedef struct _drm_via_tex_region {
+struct drm_via_tex_region {
 	unsigned char next, prev;	/* indices to form a circular LRU  */
 	unsigned char inUse;	/* owned by a client, or free? */
 	int age;		/* tracked by clients to update local LRU's */
-} drm_via_tex_region_t;
+};
 
-typedef struct _drm_via_sarea {
+struct drm_via_sarea {
 	unsigned int dirty;
 	unsigned int nbox;
 	struct drm_clip_rect boxes[VIA_NR_SAREA_CLIPRECTS];
-	drm_via_tex_region_t texList[VIA_NR_TEX_REGIONS + 1];
+	struct drm_via_tex_region texList[VIA_NR_TEX_REGIONS + 1];
 	int texAge;		/* last time texture was uploaded */
 	int ctxOwner;		/* last context to upload state */
 	int vertexPrim;
@@ -203,23 +238,23 @@ typedef struct _drm_via_sarea {
 	/* Used by the 3d driver only at this point, for pageflipping:
 	 */
 	unsigned int pfCurrentOffset;
-} drm_via_sarea_t;
+};
 
-typedef struct _drm_via_cmdbuf_size {
+struct drm_via_cmdbuf_size {
 	enum {
 		VIA_CMDBUF_SPACE = 0x01,
 		VIA_CMDBUF_LAG = 0x02
 	} func;
 	int wait;
 	uint32_t size;
-} drm_via_cmdbuf_size_t;
+};
 
-typedef enum {
+enum via_irq_seq_type {
 	VIA_IRQ_ABSOLUTE = 0x0,
 	VIA_IRQ_RELATIVE = 0x1,
 	VIA_IRQ_SIGNAL = 0x10000000,
 	VIA_IRQ_FORCE_SEQUENCE = 0x20000000
-} via_irq_seq_type_t;
+};
 
 #define VIA_IRQ_FLAGS_MASK 0xF0000000
 
@@ -235,20 +270,20 @@ enum drm_via_irqs {
 
 struct drm_via_wait_irq_request {
 	unsigned irq;
-	via_irq_seq_type_t type;
+	enum via_irq_seq_type type;
 	uint32_t sequence;
 	uint32_t signal;
 };
 
-typedef union drm_via_irqwait {
+union drm_via_irqwait {
 	struct drm_via_wait_irq_request request;
 	struct drm_wait_vblank_reply reply;
-} drm_via_irqwait_t;
+};
 
-typedef struct drm_via_blitsync {
+struct drm_via_blitsync {
 	uint32_t sync_handle;
 	unsigned engine;
-} drm_via_blitsync_t;
+};
 
 /* - * Below,"flags" is currently unused but will be used for possible future
  * extensions like kernel space bounce buffers for bad alignments and
@@ -256,7 +291,7 @@ typedef struct drm_via_blitsync {
  * interrupts.
  */
 
-typedef struct drm_via_dmablit {
+struct drm_via_dmablit {
 	uint32_t num_lines;
 	uint32_t line_length;
 
@@ -269,7 +304,18 @@ typedef struct drm_via_dmablit {
 	uint32_t flags;
 	int to_fb;
 
-	drm_via_blitsync_t sync;
-} drm_via_dmablit_t;
+	struct drm_via_blitsync sync;
+};
+
+struct drm_via_video_save_head {
+    void *pvideomem;
+    void *psystemmem;
+    int size;
+    /* token used to identify this video memory */
+    unsigned long token;
+    void *next;
+};
+
+extern struct drm_via_video_save_head *via_video_save_head;
 
 #endif				/* _VIA_DRM_H_ */
--- a/drivers/char/drm/via_drv.c
+++ b/drivers/char/drm/via_drv.c
@@ -37,10 +37,17 @@ static struct pci_device_id pciidlist[] 
 	viadrv_PCI_IDS
 };
 
+int  via_driver_open(struct drm_device *dev, struct drm_file *priv)
+{
+    priv->authenticated = 1;
+    return 0;
+}
+
 static struct drm_driver driver = {
 	.driver_features =
 	    DRIVER_USE_AGP | DRIVER_USE_MTRR | DRIVER_HAVE_IRQ |
 	    DRIVER_IRQ_SHARED | DRIVER_IRQ_VBL,
+	.open = via_driver_open,
 	.load = via_driver_load,
 	.unload = via_driver_unload,
 	.context_dtor = via_final_context,
@@ -68,8 +75,10 @@ static struct drm_driver driver = {
 		 .fasync = drm_fasync,
 	},
 	.pci_driver = {
-		 .name = DRIVER_NAME,
-		 .id_table = pciidlist,
+		.name = DRIVER_NAME,
+		.id_table = pciidlist,
+		.suspend = via_drm_suspend,
+		.resume = via_drm_resume,
 	},
 
 	.name = DRIVER_NAME,
--- a/drivers/char/drm/via_drv.h
+++ b/drivers/char/drm/via_drv.h
@@ -43,25 +43,29 @@
 #define VIA_FIRE_BUF_SIZE  1024
 #define VIA_NUM_IRQS 4
 
-typedef struct drm_via_ring_buffer {
+struct drm_via_ring_buffer {
 	drm_local_map_t map;
 	char *virtual_start;
-} drm_via_ring_buffer_t;
+};
 
 typedef uint32_t maskarray_t[5];
 
-typedef struct drm_via_irq {
+struct drm_via_irq {
 	atomic_t irq_received;
 	uint32_t pending_mask;
 	uint32_t enable_mask;
 	wait_queue_head_t irq_queue;
-} drm_via_irq_t;
+};
 
-typedef struct drm_via_private {
-	drm_via_sarea_t *sarea_priv;
+struct drm_via_private {
+	struct drm_via_sarea *sarea_priv;
 	drm_local_map_t *sarea;
 	drm_local_map_t *fb;
 	drm_local_map_t *mmio;
+    /* support managing agp in our own prev data structure */
+    drm_local_map_t *agp;
+    enum drm_agp_type agptype;
+    /* end */
 	unsigned long agpAddr;
 	wait_queue_head_t decoder_queue[VIA_NR_XVMC_LOCKS];
 	char *dma_ptr;
@@ -71,16 +75,16 @@ typedef struct drm_via_private {
 	uint32_t dma_wrap;
 	volatile uint32_t *last_pause_ptr;
 	volatile uint32_t *hw_addr_ptr;
-	drm_via_ring_buffer_t ring;
+	struct drm_via_ring_buffer ring;
 	struct timeval last_vblank;
 	int last_vblank_valid;
 	unsigned usec_per_vblank;
-	drm_via_state_t hc_state;
+	struct drm_via_state hc_state;
 	char pci_buf[VIA_PCI_BUF_SIZE];
 	const uint32_t *fire_offsets[VIA_FIRE_BUF_SIZE];
 	uint32_t num_fire_offsets;
 	int chipset;
-	drm_via_irq_t via_irqs[VIA_NUM_IRQS];
+	struct drm_via_irq via_irqs[VIA_NUM_IRQS];
 	unsigned num_irqs;
 	maskarray_t *irq_masks;
 	uint32_t irq_enable_mask;
@@ -92,9 +96,9 @@ typedef struct drm_via_private {
 	int agp_initialized;
 	unsigned long vram_offset;
 	unsigned long agp_offset;
-	drm_via_blitq_t blit_queues[VIA_NUM_BLIT_ENGINES];
+	struct drm_via_blitq blit_queues[VIA_NUM_BLIT_ENGINES];
 	uint32_t dma_diff;
-} drm_via_private_t;
+};
 
 enum via_family {
   VIA_OTHER = 0,     /* Baseline */
@@ -106,48 +110,65 @@ enum via_family {
 #define VIA_BASE ((dev_priv->mmio))
 
 #define VIA_READ(reg)		DRM_READ32(VIA_BASE, reg)
-#define VIA_WRITE(reg,val)	DRM_WRITE32(VIA_BASE, reg, val)
+#define VIA_WRITE(reg, val)	DRM_WRITE32(VIA_BASE, reg, val)
 #define VIA_READ8(reg)		DRM_READ8(VIA_BASE, reg)
-#define VIA_WRITE8(reg,val)	DRM_WRITE8(VIA_BASE, reg, val)
+#define VIA_WRITE8(reg, val)	DRM_WRITE8(VIA_BASE, reg, val)
 
 extern struct drm_ioctl_desc via_ioctls[];
 extern int via_max_ioctl;
 
-extern int via_fb_init(struct drm_device *dev, void *data, struct drm_file *file_priv);
-extern int via_mem_alloc(struct drm_device *dev, void *data, struct drm_file *file_priv);
-extern int via_mem_free(struct drm_device *dev, void *data, struct drm_file *file_priv);
-extern int via_agp_init(struct drm_device *dev, void *data, struct drm_file *file_priv);
-extern int via_map_init(struct drm_device *dev, void *data, struct drm_file *file_priv);
-extern int via_decoder_futex(struct drm_device *dev, void *data, struct drm_file *file_priv);
-extern int via_wait_irq(struct drm_device *dev, void *data, struct drm_file *file_priv);
-extern int via_dma_blit_sync( struct drm_device *dev, void *data, struct drm_file *file_priv );
-extern int via_dma_blit( struct drm_device *dev, void *data, struct drm_file *file_priv );
+extern int via_fb_init(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_mem_alloc(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_mem_free(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_agp_init(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_map_init(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_decoder_futex(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_get_drm_info(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_wait_irq(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_dma_blit_sync(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
+extern int via_dma_blit(struct drm_device *dev, void *data,
+	struct drm_file *file_priv);
 
 extern int via_driver_load(struct drm_device *dev, unsigned long chipset);
 extern int via_driver_unload(struct drm_device *dev);
 
-extern int via_init_context(struct drm_device * dev, int context);
-extern int via_final_context(struct drm_device * dev, int context);
+extern int via_init_context(struct drm_device *dev, int context);
+extern int via_final_context(struct drm_device *dev, int context);
 
-extern int via_do_cleanup_map(struct drm_device * dev);
-extern int via_driver_vblank_wait(struct drm_device * dev, unsigned int *sequence);
+extern int via_do_cleanup_map(struct drm_device *dev);
+extern int via_driver_vblank_wait(struct drm_device *dev,
+	unsigned int *sequence);
 
 extern irqreturn_t via_driver_irq_handler(DRM_IRQ_ARGS);
-extern void via_driver_irq_preinstall(struct drm_device * dev);
-extern void via_driver_irq_postinstall(struct drm_device * dev);
-extern void via_driver_irq_uninstall(struct drm_device * dev);
+extern void via_driver_irq_preinstall(struct drm_device *dev);
+extern void via_driver_irq_postinstall(struct drm_device *dev);
+extern void via_driver_irq_uninstall(struct drm_device *dev);
 
-extern int via_dma_cleanup(struct drm_device * dev);
+extern int via_dma_cleanup(struct drm_device *dev);
 extern void via_init_command_verifier(void);
-extern int via_driver_dma_quiescent(struct drm_device * dev);
-extern void via_init_futex(drm_via_private_t * dev_priv);
-extern void via_cleanup_futex(drm_via_private_t * dev_priv);
-extern void via_release_futex(drm_via_private_t * dev_priv, int context);
+extern int via_driver_dma_quiescent(struct drm_device *dev);
+extern void via_init_futex(struct drm_via_private *dev_priv);
+extern void via_cleanup_futex(struct drm_via_private *dev_priv);
+extern void via_release_futex(struct drm_via_private *dev_priv, int context);
 
-extern void via_reclaim_buffers_locked(struct drm_device *dev, struct drm_file *file_priv);
+extern void via_reclaim_buffers_locked(struct drm_device *dev,
+	struct drm_file *file_priv);
 extern void via_lastclose(struct drm_device *dev);
 
-extern void via_dmablit_handler(struct drm_device *dev, int engine, int from_irq);
+extern void via_dmablit_handler(struct drm_device *dev, int engine,
+	int from_irq);
 extern void via_init_dmablit(struct drm_device *dev);
 
+extern int via_drm_resume(struct pci_dev *dev);
+extern int via_drm_suspend(struct pci_dev *dev, pm_message_t state);
+
 #endif
--- a/drivers/char/drm/via_irq.c
+++ b/drivers/char/drm/via_irq.c
@@ -30,9 +30,10 @@
  *    Keith Whitwell <keith@tungstengraphics.com>
  *    Thomas Hellstrom <unichrome@shipmail.org>
  *
- * This code provides standard DRM access to the Via Unichrome / Pro Vertical blank
- * interrupt, as well as an infrastructure to handle other interrupts of the chip.
- * The refresh rate is also calculated for video playback sync purposes.
+ * This code provides standard DRM access to the Via Unichrome
+ * / Pro Vertical blank interrupt, as well as an infrastructure
+ * to handle other interrupts of the chip. The refresh rate is
+ * also calculated for video playback sync purposes.
  */
 
 #include "drmP.h"
@@ -99,11 +100,12 @@ static unsigned time_diff(struct timeval
 irqreturn_t via_driver_irq_handler(DRM_IRQ_ARGS)
 {
 	struct drm_device *dev = (struct drm_device *) arg;
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	u32 status;
 	int handled = 0;
 	struct timeval cur_vblank;
-	drm_via_irq_t *cur_irq = dev_priv->via_irqs;
+	struct drm_via_irq *cur_irq = dev_priv->via_irqs;
 	int i;
 
 	status = VIA_READ(VIA_REG_INTERRUPT);
@@ -133,11 +135,12 @@ irqreturn_t via_driver_irq_handler(DRM_I
 			atomic_inc(&cur_irq->irq_received);
 			DRM_WAKEUP(&cur_irq->irq_queue);
 			handled = 1;
-			if (dev_priv->irq_map[drm_via_irq_dma0_td] == i) {
+			if (dev_priv->irq_map[drm_via_irq_dma0_td] == i)
 				via_dmablit_handler(dev, 0, 1);
-			} else if (dev_priv->irq_map[drm_via_irq_dma1_td] == i) {
+			else if (dev_priv->irq_map[drm_via_irq_dma1_td] ==
+				i)
 				via_dmablit_handler(dev, 1, 1);
-			}
+
 		}
 		cur_irq++;
 	}
@@ -151,7 +154,8 @@ irqreturn_t via_driver_irq_handler(DRM_I
 		return IRQ_NONE;
 }
 
-static __inline__ void viadrv_acknowledge_irqs(drm_via_private_t * dev_priv)
+static inline void
+viadrv_acknowledge_irqs(struct drm_via_private *dev_priv)
 {
 	u32 status;
 
@@ -163,9 +167,10 @@ static __inline__ void viadrv_acknowledg
 	}
 }
 
-int via_driver_vblank_wait(struct drm_device * dev, unsigned int *sequence)
+int via_driver_vblank_wait(struct drm_device *dev, unsigned int *sequence)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	unsigned int cur_vblank;
 	int ret = 0;
 
@@ -191,12 +196,13 @@ int via_driver_vblank_wait(struct drm_de
 }
 
 static int
-via_driver_irq_wait(struct drm_device * dev, unsigned int irq, int force_sequence,
-		    unsigned int *sequence)
+via_driver_irq_wait(struct drm_device *dev, unsigned int irq,
+	int force_sequence, unsigned int *sequence)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	unsigned int cur_irq_sequence;
-	drm_via_irq_t *cur_irq;
+	struct drm_via_irq *cur_irq;
 	int ret = 0;
 	maskarray_t *masks;
 	int real_irq;
@@ -243,11 +249,12 @@ via_driver_irq_wait(struct drm_device * 
  * drm_dma.h hooks
  */
 
-void via_driver_irq_preinstall(struct drm_device * dev)
+void via_driver_irq_preinstall(struct drm_device *dev)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	u32 status;
-	drm_via_irq_t *cur_irq;
+	struct drm_via_irq *cur_irq;
 	int i;
 
 	DRM_DEBUG("dev_priv: %p\n", dev_priv);
@@ -292,9 +299,10 @@ void via_driver_irq_preinstall(struct dr
 	}
 }
 
-void via_driver_irq_postinstall(struct drm_device * dev)
+void via_driver_irq_postinstall(struct drm_device *dev)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	u32 status;
 
 	DRM_DEBUG("\n");
@@ -311,9 +319,10 @@ void via_driver_irq_postinstall(struct d
 	}
 }
 
-void via_driver_irq_uninstall(struct drm_device * dev)
+void via_driver_irq_uninstall(struct drm_device *dev)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	u32 status;
 
 	DRM_DEBUG("\n");
@@ -330,13 +339,15 @@ void via_driver_irq_uninstall(struct drm
 	}
 }
 
-int via_wait_irq(struct drm_device *dev, void *data, struct drm_file *file_priv)
+int via_wait_irq(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
-	drm_via_irqwait_t *irqwait = data;
+	union drm_via_irqwait *irqwait = data;
 	struct timeval now;
 	int ret = 0;
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
-	drm_via_irq_t *cur_irq = dev_priv->via_irqs;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
+	struct drm_via_irq *cur_irq = dev_priv->via_irqs;
 	int force_sequence;
 
 	if (!dev->irq)
@@ -352,7 +363,8 @@ int via_wait_irq(struct drm_device *dev,
 
 	switch (irqwait->request.type & ~VIA_IRQ_FLAGS_MASK) {
 	case VIA_IRQ_RELATIVE:
-		irqwait->request.sequence += atomic_read(&cur_irq->irq_received);
+		irqwait->request.sequence +=
+			atomic_read(&cur_irq->irq_received);
 		irqwait->request.type &= ~_DRM_VBLANK_RELATIVE;
 	case VIA_IRQ_ABSOLUTE:
 		break;
--- a/drivers/char/drm/via_map.c
+++ b/drivers/char/drm/via_map.c
@@ -25,9 +25,11 @@
 #include "via_drm.h"
 #include "via_drv.h"
 
-static int via_do_init_map(struct drm_device * dev, drm_via_init_t * init)
+static int associate;
+
+static int via_do_init_map(struct drm_device *dev, struct drm_via_init *init)
 {
-	drm_via_private_t *dev_priv = dev->dev_private;
+	struct drm_via_private *dev_priv = dev->dev_private;
 
 	DRM_DEBUG("\n");
 
@@ -55,7 +57,7 @@ static int via_do_init_map(struct drm_de
 	}
 
 	dev_priv->sarea_priv =
-	    (drm_via_sarea_t *) ((u8 *) dev_priv->sarea->handle +
+	    (struct drm_via_sarea *) ((u8 *) dev_priv->sarea->handle +
 				 init->sarea_priv_offset);
 
 	dev_priv->agpAddr = init->agpAddr;
@@ -65,19 +67,43 @@ static int via_do_init_map(struct drm_de
 	via_init_dmablit(dev);
 
 	dev->dev_private = (void *)dev_priv;
+
+	/* from doing this, we has the stuff
+	 *in prev data structure to manage agp
+	 */
+	if (init->agp_type != DISABLED) {
+		dev_priv->agp = drm_core_findmap(dev, init->agp_offset);
+
+		if (!dev_priv->agp) {
+			DRM_ERROR("failed to find dma buffer region!\n");
+			return -EINVAL;
+		}
+
+		if (init->agp_type == AGP_DOUBLE_BUFFER)
+			dev_priv->agptype = AGP_DOUBLE_BUFFER;
+
+		if (init->agp_type == AGP_RING_BUFFER)
+			dev_priv->agptype = AGP_RING_BUFFER;
+	} else {
+		dev_priv->agptype = DISABLED;
+		dev_priv->agp = 0;
+	}
+	/* end */
+
 	return 0;
 }
 
-int via_do_cleanup_map(struct drm_device * dev)
+int via_do_cleanup_map(struct drm_device *dev)
 {
 	via_dma_cleanup(dev);
 
 	return 0;
 }
 
-int via_map_init(struct drm_device *dev, void *data, struct drm_file *file_priv)
+int via_map_init(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
-	drm_via_init_t *init = data;
+	struct drm_via_init *init = data;
 
 	DRM_DEBUG("\n");
 
@@ -93,10 +119,17 @@ int via_map_init(struct drm_device *dev,
 
 int via_driver_load(struct drm_device *dev, unsigned long chipset)
 {
-	drm_via_private_t *dev_priv;
+	struct drm_via_private *dev_priv;
 	int ret = 0;
 
-	dev_priv = drm_calloc(1, sizeof(drm_via_private_t), DRM_MEM_DRIVER);
+	if (!associate) {
+		pci_set_drvdata(dev->pdev, dev);
+		dev->pdev->driver = &dev->driver->pci_driver;
+		associate = 1;
+	}
+
+	dev_priv = drm_calloc(1,
+			sizeof(struct drm_via_private), DRM_MEM_DRIVER);
 	if (dev_priv == NULL)
 		return -ENOMEM;
 
@@ -105,19 +138,37 @@ int via_driver_load(struct drm_device *d
 	dev_priv->chipset = chipset;
 
 	ret = drm_sman_init(&dev_priv->sman, 2, 12, 8);
-	if (ret) {
+	if (ret)
 		drm_free(dev_priv, sizeof(*dev_priv), DRM_MEM_DRIVER);
-	}
+
 	return ret;
 }
 
 int via_driver_unload(struct drm_device *dev)
 {
-	drm_via_private_t *dev_priv = dev->dev_private;
+	struct drm_via_private *dev_priv = dev->dev_private;
 
 	drm_sman_takedown(&dev_priv->sman);
 
-	drm_free(dev_priv, sizeof(drm_via_private_t), DRM_MEM_DRIVER);
+	drm_free(dev_priv, sizeof(struct drm_via_private), DRM_MEM_DRIVER);
+
+	return 0;
+}
 
+int via_get_drm_info(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
+{
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *)dev->dev_private;
+	struct drm_via_info info;
+
+	if (copy_from_user(&info, data, sizeof(info)))
+		return -EFAULT;
+	info.RegSize = dev_priv->mmio->size;
+	info.AgpSize = dev_priv->agp->size;
+	info.RegHandle = dev_priv->mmio->offset;
+	info.AgpHandle = dev_priv->agp->offset;
+	if (copy_to_user((struct drm_via_info *)data, &info, sizeof(info)))
+		return -EFAULT;
 	return 0;
 }
--- a/drivers/char/drm/via_mm.c
+++ b/drivers/char/drm/via_mm.c
@@ -1,42 +1,47 @@
 /*
- * Copyright 2006 Tungsten Graphics Inc., Bismarck, ND., USA.
- * All rights reserved.
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation
- * the rights to use, copy, modify, merge, publish, distribute, sub license,
- * and/or sell copies of the Software, and to permit persons to whom the
- * Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice (including the
- * next paragraph) shall be included in all copies or substantial portions
- * of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
- * THE AUTHORS OR COPYRIGHT HOLDERS AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
- * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
- * DEALINGS IN THE SOFTWARE.
- */
+* Copyright 2006 Tungsten Graphics Inc., Bismarck, ND., USA.
+* All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sub license,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright notice and this permission notice (including the
+* next paragraph) shall be included in all copies or substantial portions
+* of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY
+* CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+* TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR
+* THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+*/
+
 /*
- * Authors: Thomas Hellström <thomas-at-tungstengraphics-dot-com>
- */
+* Authors: Thomas Hellström <thomas-at-tungstengraphics-dot-com>
+*/
 
 #include "drmP.h"
 #include "via_drm.h"
 #include "via_drv.h"
 #include "drm_sman.h"
 
+struct drm_via_video_save_head *via_video_save_head;
+
 #define VIA_MM_ALIGN_SHIFT 4
-#define VIA_MM_ALIGN_MASK ( (1 << VIA_MM_ALIGN_SHIFT) - 1)
+#define VIA_MM_ALIGN_MASK ((1 << VIA_MM_ALIGN_SHIFT) - 1)
 
-int via_agp_init(struct drm_device *dev, void *data, struct drm_file *file_priv)
+int via_agp_init(struct drm_device *dev, void *data,
+struct drm_file *file_priv)
 {
-	drm_via_agp_t *agp = data;
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_agp *agp = data;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	int ret;
 
 	mutex_lock(&dev->struct_mutex);
@@ -57,10 +62,16 @@ int via_agp_init(struct drm_device *dev,
 	return 0;
 }
 
+/*Henry:For via_fb_alloc/free used by video*/
+static void *global_dev;
+static void *global_file_priv;
+/*Henry:End*/
+
 int via_fb_init(struct drm_device *dev, void *data, struct drm_file *file_priv)
 {
-	drm_via_fb_t *fb = data;
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_fb *fb = data;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	int ret;
 
 	mutex_lock(&dev->struct_mutex);
@@ -79,13 +90,19 @@ int via_fb_init(struct drm_device *dev, 
 	mutex_unlock(&dev->struct_mutex);
 	DRM_DEBUG("offset = %u, size = %u\n", fb->offset, fb->size);
 
+	/*Henry:For via_fb_alloc/free used by video*/
+	global_dev = dev;
+	global_file_priv = file_priv;
+	/*Henry:End*/
+
 	return 0;
 
 }
 
 int via_final_context(struct drm_device *dev, int context)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 
 	via_release_futex(dev_priv, context);
 
@@ -103,7 +120,8 @@ int via_final_context(struct drm_device 
 
 void via_lastclose(struct drm_device *dev)
 {
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 
 	if (!dev_priv)
 		return;
@@ -115,38 +133,134 @@ void via_lastclose(struct drm_device *de
 	mutex_unlock(&dev->struct_mutex);
 }
 
+static int via_videomem_presave_ok(struct drm_via_private *dev_priv,
+	struct drm_via_mem *mem)
+{
+	void *pvideomem = 0, *psystemmem = 0;
+	struct drm_via_video_save_head *pnode = 0;
+
+	if (!mem || !mem->size || (mem->type != VIA_MEM_VIDEO_SAVE))
+		return 0;
+
+	/* here the mem->offset is the absolute address,
+	 *not the offset within videomem
+	 */
+	pvideomem =
+		(void *)ioremap(dev_priv->fb->offset+mem->offset, mem->size);
+	if (!pvideomem)
+		return 0;
+	psystemmem = kmalloc(mem->size, GFP_KERNEL);
+	if (!psystemmem) {
+		iounmap(pvideomem);
+		return 0;
+	}
+
+	/* map success, then save this information into
+	 * a data structure for later saving usage
+	 */
+	pnode = kmalloc(sizeof(struct drm_via_video_save_head), GFP_KERNEL);
+
+	if (!pnode) {
+		iounmap(pvideomem);
+		kfree(psystemmem);
+		return 0;
+	}
+
+	pnode->next = 0;
+	pnode->psystemmem = psystemmem;
+	pnode->pvideomem = pvideomem;
+	pnode->size = mem->size;
+	pnode->token = mem->offset;
+
+	/* insert this node into list */
+	if (!via_video_save_head)
+		via_video_save_head = pnode;
+	else {
+		pnode->next = via_video_save_head;
+		via_video_save_head = pnode;
+	}
+
+	return 1;
+
+}
+
+static int via_videomem_housekeep_ok(struct drm_via_mem *mem)
+{
+	struct drm_via_video_save_head **ppnode = 0;
+	struct drm_via_video_save_head *tmpnode = 0;
+
+	/* if this mem's token match with one node of the list */
+
+	for (ppnode = &via_video_save_head; *ppnode;
+		ppnode = (struct drm_via_video_save_head **)
+			(&((*ppnode)->next))) {
+		if ((*ppnode)->token == mem->offset)
+			break;
+
+	}
+
+	if (*ppnode == 0)
+
+		/* not found, the user may specify the wrong mem node to free */
+		return 0;
+
+	/* delete this node from the list and then free
+	 * all the mem to avoid memory leak
+	 */
+	tmpnode = *ppnode;
+	*ppnode = (*ppnode)->next;
+	iounmap(tmpnode->pvideomem);
+	kfree(tmpnode->psystemmem);
+	kfree(tmpnode);
+
+	return 1;
+}
+
 int via_mem_alloc(struct drm_device *dev, void *data,
 		  struct drm_file *file_priv)
 {
-	drm_via_mem_t *mem = data;
+	struct drm_via_mem *mem = data;
 	int retval = 0;
 	struct drm_memblock_item *item;
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	unsigned long tmpSize;
 
-	if (mem->type > VIA_MEM_AGP) {
+	if (mem->type > VIA_MEM_VIDEO_SAVE) {
 		DRM_ERROR("Unknown memory type allocation\n");
 		return -EINVAL;
 	}
 	mutex_lock(&dev->struct_mutex);
-	if (0 == ((mem->type == VIA_MEM_VIDEO) ? dev_priv->vram_initialized :
-		      dev_priv->agp_initialized)) {
-		DRM_ERROR
-		    ("Attempt to allocate from uninitialized memory manager.\n");
+	if (0 ==
+	((mem->type == VIA_MEM_VIDEO || mem->type == VIA_MEM_VIDEO_SAVE) ?
+	dev_priv->vram_initialized : dev_priv->agp_initialized)) {
+		DRM_ERROR("Attempt to allocate from \
+			uninitialized memory manager.\n");
 		mutex_unlock(&dev->struct_mutex);
 		return -EINVAL;
 	}
 
 	tmpSize = (mem->size + VIA_MM_ALIGN_MASK) >> VIA_MM_ALIGN_SHIFT;
-	item = drm_sman_alloc(&dev_priv->sman, mem->type, tmpSize, 0,
-			      (unsigned long)file_priv);
+	item = drm_sman_alloc(&dev_priv->sman,
+		(mem->type == VIA_MEM_VIDEO_SAVE?VIA_MEM_VIDEO:mem->type),
+		tmpSize, 0, (unsigned long)file_priv);
 	mutex_unlock(&dev->struct_mutex);
 	if (item) {
-		mem->offset = ((mem->type == VIA_MEM_VIDEO) ?
-			      dev_priv->vram_offset : dev_priv->agp_offset) +
-		    (item->mm->
-		     offset(item->mm, item->mm_info) << VIA_MM_ALIGN_SHIFT);
+		mem->offset =
+		((mem->type == VIA_MEM_VIDEO ||
+			mem->type == VIA_MEM_VIDEO_SAVE) ?
+		dev_priv->vram_offset : dev_priv->agp_offset) +
+		(item->mm->offset(item->mm, item->mm_info) <<
+		VIA_MM_ALIGN_SHIFT);
 		mem->index = item->user_hash.key;
+		if (mem->type == VIA_MEM_VIDEO_SAVE) {
+			if (!via_videomem_presave_ok(dev_priv, mem)) {
+				mutex_lock(&dev->struct_mutex);
+				drm_sman_free_key(&dev_priv->sman, mem->index);
+				mutex_unlock(&dev->struct_mutex);
+				retval = -ENOMEM;
+			}
+		}
 	} else {
 		mem->offset = 0;
 		mem->size = 0;
@@ -158,14 +272,20 @@ int via_mem_alloc(struct drm_device *dev
 	return retval;
 }
 
-int via_mem_free(struct drm_device *dev, void *data, struct drm_file *file_priv)
+int via_mem_free(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
-	drm_via_private_t *dev_priv = dev->dev_private;
-	drm_via_mem_t *mem = data;
+	struct drm_via_private *dev_priv = dev->dev_private;
+	struct drm_via_mem *mem = data;
 	int ret;
 
 	mutex_lock(&dev->struct_mutex);
 	ret = drm_sman_free_key(&dev_priv->sman, mem->index);
+	if (mem->type == VIA_MEM_VIDEO_SAVE) {
+		if (!via_videomem_housekeep_ok(mem))
+			ret = -EINVAL;
+	}
+
 	mutex_unlock(&dev->struct_mutex);
 	DRM_DEBUG("free = 0x%lx\n", mem->index);
 
@@ -173,10 +293,10 @@ int via_mem_free(struct drm_device *dev,
 }
 
 
-void via_reclaim_buffers_locked(struct drm_device * dev,
+void via_reclaim_buffers_locked(struct drm_device *dev,
 				struct drm_file *file_priv)
 {
-	drm_via_private_t *dev_priv = dev->dev_private;
+	struct drm_via_private *dev_priv = dev->dev_private;
 
 	mutex_lock(&dev->struct_mutex);
 	if (drm_sman_owner_clean(&dev_priv->sman, (unsigned long)file_priv)) {
@@ -184,11 +304,36 @@ void via_reclaim_buffers_locked(struct d
 		return;
 	}
 
-	if (dev->driver->dma_quiescent) {
+	if (dev->driver->dma_quiescent)
 		dev->driver->dma_quiescent(dev);
-	}
+
 
 	drm_sman_owner_cleanup(&dev_priv->sman, (unsigned long)file_priv);
 	mutex_unlock(&dev->struct_mutex);
 	return;
 }
+
+/*Henry:For via_fb_alloc/free used by video*/
+static int via_fb_alloc(struct drm_via_mem *mem)
+{
+	struct drm_device *dev = global_dev;
+	struct drm_file *file_priv = global_file_priv;
+
+	if (dev && file_priv)
+		return via_mem_alloc(dev, mem, file_priv);
+	else
+		return -EINVAL;
+}
+EXPORT_SYMBOL(via_fb_alloc);
+
+static int via_fb_free(struct drm_via_mem *mem)
+{
+	struct drm_device *dev = global_dev;
+	struct drm_file *file_priv = global_file_priv;
+
+	if (dev && file_priv)
+		return via_mem_free(dev, mem, file_priv);
+	else
+		return -EINVAL;
+}
+EXPORT_SYMBOL(via_fb_free);
--- a/drivers/char/drm/via_verifier.c
+++ b/drivers/char/drm/via_verifier.c
@@ -1,32 +1,32 @@
 /*
- * Copyright 2004 The Unichrome Project. All Rights Reserved.
- * Copyright 2005 Thomas Hellstrom. All Rights Reserved.
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation
- * the rights to use, copy, modify, merge, publish, distribute, sub license,
- * and/or sell copies of the Software, and to permit persons to whom the
- * Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice (including the
- * next paragraph) shall be included in all copies or substantial portions
- * of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
- * THE AUTHOR(S), AND/OR THE COPYRIGHT HOLDER(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
- * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
- * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
- * DEALINGS IN THE SOFTWARE.
- *
- * Author: Thomas Hellstrom 2004, 2005.
- * This code was written using docs obtained under NDA from VIA Inc.
- *
- * Don't run this code directly on an AGP buffer. Due to cache problems it will
- * be very slow.
- */
+* Copyright 2004 The Unichrome Project. All Rights Reserved.
+* Copyright 2005 Thomas Hellstrom. All Rights Reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sub license,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright notice and this permission notice (including the
+* next paragraph) shall be included in all copies or substantial portions
+* of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+* THE AUTHOR(S), AND/OR THE COPYRIGHT HOLDER(S) BE LIABLE FOR ANY CLAIM, DAMAGES
+* OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+* ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*
+* Author: Thomas Hellstrom 2004, 2005.
+* This code was written using docs obtained under NDA from VIA Inc.
+*
+* Don't run this code directly on an AGP buffer. Due to cache problems it will
+* be very slow.
+*/
 
 #include "via_3d_reg.h"
 #include "drmP.h"
@@ -35,16 +35,16 @@
 #include "via_verifier.h"
 #include "via_drv.h"
 
-typedef enum {
+enum verifier_state {
 	state_command,
 	state_header2,
 	state_header1,
 	state_vheader5,
 	state_vheader6,
 	state_error
-} verifier_state_t;
+};
 
-typedef enum {
+enum hazard {
 	no_check = 0,
 	check_for_header2,
 	check_for_header1,
@@ -72,7 +72,7 @@ typedef enum {
 	check_for_vertex_count,
 	check_number_texunits,
 	forbidden_command
-} hazard_t;
+};
 
 /*
  * Associates each hazard above with a possible multi-command
@@ -81,7 +81,7 @@ typedef enum {
  * that does not include any part of the address.
  */
 
-static drm_via_sequence_t seqs[] = {
+static enum drm_via_sequence seqs[] = {
 	no_sequence,
 	no_sequence,
 	no_sequence,
@@ -109,12 +109,12 @@ static drm_via_sequence_t seqs[] = {
 	no_sequence
 };
 
-typedef struct {
+struct hz_init {
 	unsigned int code;
-	hazard_t hz;
-} hz_init_t;
+	enum hazard hz;
+};
 
-static hz_init_t init_table1[] = {
+static struct hz_init init_table1[] = {
 	{0xf2, check_for_header2_err},
 	{0xf0, check_for_header1_err},
 	{0xee, check_for_fire},
@@ -165,7 +165,7 @@ static hz_init_t init_table1[] = {
 	{0x7D, check_for_vertex_count}
 };
 
-static hz_init_t init_table2[] = {
+static struct hz_init init_table2[] = {
 	{0xf2, check_for_header2_err},
 	{0xf0, check_for_header1_err},
 	{0xee, check_for_fire},
@@ -223,19 +223,19 @@ static hz_init_t init_table2[] = {
 	{0x93, no_check}
 };
 
-static hz_init_t init_table3[] = {
+static struct hz_init init_table3[] = {
 	{0xf2, check_for_header2_err},
 	{0xf0, check_for_header1_err},
 	{0xcc, check_for_dummy},
 	{0x00, check_number_texunits}
 };
 
-static hazard_t table1[256];
-static hazard_t table2[256];
-static hazard_t table3[256];
+static enum hazard table1[256];
+static enum hazard table2[256];
+static enum hazard table3[256];
 
-static __inline__ int
-eat_words(const uint32_t ** buf, const uint32_t * buf_end, unsigned num_words)
+static inline int
+eat_words(const uint32_t **buf, const uint32_t *buf_end, unsigned num_words)
 {
 	if ((buf_end - *buf) >= num_words) {
 		*buf += num_words;
@@ -249,18 +249,16 @@ eat_words(const uint32_t ** buf, const u
  * Partially stolen from drm_memory.h
  */
 
-static __inline__ drm_local_map_t *via_drm_lookup_agp_map(drm_via_state_t *seq,
-						    unsigned long offset,
-						    unsigned long size,
-						    struct drm_device * dev)
+static inline drm_local_map_t *via_drm_lookup_agp_map(
+struct drm_via_state *seq, unsigned long offset, unsigned long size,
+struct drm_device *dev)
 {
 	struct drm_map_list *r_list;
 	drm_local_map_t *map = seq->map_cache;
 
 	if (map && map->offset <= offset
-	    && (offset + size) <= (map->offset + map->size)) {
-		return map;
-	}
+	    && (offset + size) <= (map->offset + map->size))
+	    return map;
 
 	list_for_each_entry(r_list, &dev->maplist, head) {
 		map = r_list->map;
@@ -286,7 +284,7 @@ static __inline__ drm_local_map_t *via_d
  * very little CPU time.
  */
 
-static __inline__ int finish_current_sequence(drm_via_state_t * cur_seq)
+static inline int finish_current_sequence(struct drm_via_state *cur_seq)
 {
 	switch (cur_seq->unfinished) {
 	case z_address:
@@ -343,14 +341,14 @@ static __inline__ int finish_current_seq
 	return 0;
 }
 
-static __inline__ int
-investigate_hazard(uint32_t cmd, hazard_t hz, drm_via_state_t * cur_seq)
+static inline int
+investigate_hazard(uint32_t cmd, enum hazard hz, struct drm_via_state *cur_seq)
 {
 	register uint32_t tmp, *tmp_addr;
 
 	if (cur_seq->unfinished && (cur_seq->unfinished != seqs[hz])) {
-		int ret;
-		if ((ret = finish_current_sequence(cur_seq)))
+		int ret = finish_current_sequence(cur_seq);
+		if (ret)
 			return ret;
 	}
 
@@ -453,11 +451,11 @@ investigate_hazard(uint32_t cmd, hazard_
 			cur_seq->tex_npot[cur_seq->texture] = 1;
 		} else {
 			cur_seq->pitch[cur_seq->texture][tmp] =
-				(cmd & HC_HTXnLnPitE_MASK) >> HC_HTXnLnPitE_SHIFT;
+			(cmd & HC_HTXnLnPitE_MASK) >> HC_HTXnLnPitE_SHIFT;
 			cur_seq->tex_npot[cur_seq->texture] = 0;
 			if (cmd & 0x000FFFFF) {
 				DRM_ERROR
-					("Unimplemented texture level 0 pitch mode.\n");
+				("Unimplemented texture level 0 pitch mode.\n");
 				return 2;
 			}
 		}
@@ -494,7 +492,8 @@ investigate_hazard(uint32_t cmd, hazard_
 		return 0;
 	case check_texture_addr_mode:
 		cur_seq->unfinished = tex_address;
-		if (2 == (tmp = cmd & 0x00000003)) {
+		tmp = cmd & 0x00000003;
+		if (2 == tmp) {
 			DRM_ERROR
 			    ("Attempt to fetch texture from system memory.\n");
 			return 2;
@@ -516,12 +515,12 @@ investigate_hazard(uint32_t cmd, hazard_
 	return 2;
 }
 
-static __inline__ int
-via_check_prim_list(uint32_t const **buffer, const uint32_t * buf_end,
-		    drm_via_state_t * cur_seq)
+static inline int
+via_check_prim_list(uint32_t const **buffer, const uint32_t *buf_end,
+		    struct drm_via_state *cur_seq)
 {
-	drm_via_private_t *dev_priv =
-	    (drm_via_private_t *) cur_seq->dev->dev_private;
+	struct drm_via_private *dev_priv =
+	    (struct drm_via_private *) cur_seq->dev->dev_private;
 	uint32_t a_fire, bcmd, dw_count;
 	int ret = 0;
 	int have_fire;
@@ -596,12 +595,13 @@ via_check_prim_list(uint32_t const **buf
 			if ((*buf == HALCYON_HEADER2) ||
 			    ((*buf & HALCYON_FIREMASK) == HALCYON_FIRECMD)) {
 				DRM_ERROR("Missing Vertex Fire command, "
-					  "Stray Vertex Fire command  or verifier "
+				"Stray Vertex Fire command  or verifier "
 					  "lost sync.\n");
 				ret = 1;
 				break;
 			}
-			if ((ret = eat_words(&buf, buf_end, dw_count)))
+			ret = eat_words(&buf, buf_end, dw_count);
+			if (ret)
 				break;
 		}
 		if (buf >= buf_end && !have_fire) {
@@ -620,15 +620,15 @@ via_check_prim_list(uint32_t const **buf
 	return ret;
 }
 
-static __inline__ verifier_state_t
-via_check_header2(uint32_t const **buffer, const uint32_t * buf_end,
-		  drm_via_state_t * hc_state)
+static inline enum verifier_state
+via_check_header2(uint32_t const **buffer, const uint32_t *buf_end,
+		  struct drm_via_state *hc_state)
 {
 	uint32_t cmd;
 	int hz_mode;
-	hazard_t hz;
+	enum hazard hz;
 	const uint32_t *buf = *buffer;
-	const hazard_t *hz_table;
+	const enum hazard *hz_table;
 
 	if ((buf_end - buf) < 2) {
 		DRM_ERROR
@@ -693,8 +693,10 @@ via_check_header2(uint32_t const **buffe
 
 	while (buf < buf_end) {
 		cmd = *buf++;
-		if ((hz = hz_table[cmd >> 24])) {
-			if ((hz_mode = investigate_hazard(cmd, hz, hc_state))) {
+		hz = hz_table[cmd >> 24];
+		if (hz) {
+			hz_mode = investigate_hazard(cmd, hz, hc_state);
+			if (hz_mode) {
 				if (hz_mode == 1) {
 					buf--;
 					break;
@@ -702,20 +704,19 @@ via_check_header2(uint32_t const **buffe
 				return state_error;
 			}
 		} else if (hc_state->unfinished &&
-			   finish_current_sequence(hc_state)) {
+			   finish_current_sequence(hc_state))
 			return state_error;
-		}
+
 	}
-	if (hc_state->unfinished && finish_current_sequence(hc_state)) {
+	if (hc_state->unfinished && finish_current_sequence(hc_state))
 		return state_error;
-	}
 	*buffer = buf;
 	return state_command;
 }
 
-static __inline__ verifier_state_t
-via_parse_header2(drm_via_private_t * dev_priv, uint32_t const **buffer,
-		  const uint32_t * buf_end, int *fire_count)
+static inline enum verifier_state
+via_parse_header2(struct drm_via_private *dev_priv, uint32_t const **buffer,
+		  const uint32_t *buf_end, int *fire_count)
 {
 	uint32_t cmd;
 	const uint32_t *buf = *buffer;
@@ -762,7 +763,7 @@ via_parse_header2(drm_via_private_t * de
 	return state_command;
 }
 
-static __inline__ int verify_mmio_address(uint32_t address)
+static inline int verify_mmio_address(uint32_t address)
 {
 	if ((address > 0x3FF) && (address < 0xC00)) {
 		DRM_ERROR("Invalid VIDEO DMA command. "
@@ -780,8 +781,8 @@ static __inline__ int verify_mmio_addres
 	return 0;
 }
 
-static __inline__ int
-verify_video_tail(uint32_t const **buffer, const uint32_t * buf_end,
+static inline int
+verify_video_tail(uint32_t const **buffer, const uint32_t *buf_end,
 		  uint32_t dwords)
 {
 	const uint32_t *buf = *buffer;
@@ -800,12 +801,12 @@ verify_video_tail(uint32_t const **buffe
 	return 0;
 }
 
-static __inline__ verifier_state_t
-via_check_header1(uint32_t const **buffer, const uint32_t * buf_end)
+static inline enum verifier_state
+via_check_header1(uint32_t const **buffer, const uint32_t *buf_end)
 {
 	uint32_t cmd;
 	const uint32_t *buf = *buffer;
-	verifier_state_t ret = state_command;
+	enum verifier_state ret = state_command;
 
 	while (buf < buf_end) {
 		cmd = *buf;
@@ -813,14 +814,15 @@ via_check_header1(uint32_t const **buffe
 		    (cmd < ((0xC00 >> 2) | HALCYON_HEADER1))) {
 			if ((cmd & HALCYON_HEADER1MASK) != HALCYON_HEADER1)
 				break;
-			DRM_ERROR("Invalid HALCYON_HEADER1 command. "
-				  "Attempt to access 3D- or command burst area.\n");
+			DRM_ERROR("Invalid HALCYON_HEADER1 command. " \
+				  "Attempt to access 3D- or command burst \
+				  area.\n");
 			ret = state_error;
 			break;
 		} else if (cmd > ((0xCFF >> 2) | HALCYON_HEADER1)) {
 			if ((cmd & HALCYON_HEADER1MASK) != HALCYON_HEADER1)
 				break;
-			DRM_ERROR("Invalid HALCYON_HEADER1 command. "
+			DRM_ERROR("Invalid HALCYON_HEADER1 command. " \
 				  "Attempt to access VGA registers.\n");
 			ret = state_error;
 			break;
@@ -832,9 +834,9 @@ via_check_header1(uint32_t const **buffe
 	return ret;
 }
 
-static __inline__ verifier_state_t
-via_parse_header1(drm_via_private_t * dev_priv, uint32_t const **buffer,
-		  const uint32_t * buf_end)
+static inline enum verifier_state
+via_parse_header1(struct drm_via_private *dev_priv, uint32_t const **buffer,
+		  const uint32_t *buf_end)
 {
 	register uint32_t cmd;
 	const uint32_t *buf = *buffer;
@@ -850,8 +852,8 @@ via_parse_header1(drm_via_private_t * de
 	return state_command;
 }
 
-static __inline__ verifier_state_t
-via_check_vheader5(uint32_t const **buffer, const uint32_t * buf_end)
+static inline enum verifier_state
+via_check_vheader5(uint32_t const **buffer, const uint32_t *buf_end)
 {
 	uint32_t data;
 	const uint32_t *buf = *buffer;
@@ -883,9 +885,9 @@ via_check_vheader5(uint32_t const **buff
 
 }
 
-static __inline__ verifier_state_t
-via_parse_vheader5(drm_via_private_t * dev_priv, uint32_t const **buffer,
-		   const uint32_t * buf_end)
+static inline enum verifier_state
+via_parse_vheader5(struct drm_via_private *dev_priv,
+		uint32_t const **buffer, const uint32_t *buf_end)
 {
 	uint32_t addr, count, i;
 	const uint32_t *buf = *buffer;
@@ -893,17 +895,17 @@ via_parse_vheader5(drm_via_private_t * d
 	addr = *buf++ & ~VIA_VIDEOMASK;
 	i = count = *buf;
 	buf += 3;
-	while (i--) {
+	while (i--)
 		VIA_WRITE(addr, *buf++);
-	}
+
 	if (count & 3)
 		buf += 4 - (count & 3);
 	*buffer = buf;
 	return state_command;
 }
 
-static __inline__ verifier_state_t
-via_check_vheader6(uint32_t const **buffer, const uint32_t * buf_end)
+static inline enum verifier_state
+via_check_vheader6(uint32_t const **buffer, const uint32_t *buf_end)
 {
 	uint32_t data;
 	const uint32_t *buf = *buffer;
@@ -939,9 +941,9 @@ via_check_vheader6(uint32_t const **buff
 	return state_command;
 }
 
-static __inline__ verifier_state_t
-via_parse_vheader6(drm_via_private_t * dev_priv, uint32_t const **buffer,
-		   const uint32_t * buf_end)
+static inline enum verifier_state
+via_parse_vheader6(struct drm_via_private *dev_priv,
+		uint32_t const **buffer, const uint32_t *buf_end)
 {
 
 	uint32_t addr, count, i;
@@ -961,16 +963,17 @@ via_parse_vheader6(drm_via_private_t * d
 }
 
 int
-via_verify_command_stream(const uint32_t * buf, unsigned int size,
-			  struct drm_device * dev, int agp)
+via_verify_command_stream(const uint32_t *buf, unsigned int size,
+			  struct drm_device *dev, int agp)
 {
 
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
-	drm_via_state_t *hc_state = &dev_priv->hc_state;
-	drm_via_state_t saved_state = *hc_state;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
+	struct drm_via_state *hc_state = &dev_priv->hc_state;
+	struct drm_via_state saved_state = *hc_state;
 	uint32_t cmd;
 	const uint32_t *buf_end = buf + (size >> 2);
-	verifier_state_t state = state_command;
+	enum verifier_state state = state_command;
 	int cme_video;
 	int supported_3d;
 
@@ -1002,8 +1005,8 @@ via_verify_command_stream(const uint32_t
 			state = via_check_vheader6(&buf, buf_end);
 			break;
 		case state_command:
-			if ((HALCYON_HEADER2 == (cmd = *buf)) &&
-			    supported_3d)
+			cmd = *buf;
+			if ((HALCYON_HEADER2 == cmd) && supported_3d)
 				state = state_header2;
 			else if ((cmd & HALCYON_HEADER1MASK) == HALCYON_HEADER1)
 				state = state_header1;
@@ -1014,12 +1017,12 @@ via_verify_command_stream(const uint32_t
 				 && (cmd & VIA_VIDEOMASK) == VIA_VIDEO_HEADER6)
 				state = state_vheader6;
 			else if ((cmd == HALCYON_HEADER2) && !supported_3d) {
-				DRM_ERROR("Accelerated 3D is not supported on this chipset yet.\n");
+				DRM_ERROR("Accelerated 3D is not \
+					supported on this chipset yet.\n");
 				state = state_error;
 			} else {
-				DRM_ERROR
-				    ("Invalid / Unimplemented DMA HEADER command. 0x%x\n",
-				     cmd);
+				DRM_ERROR("Invalid / Unimplemented DMA \
+					HEADER command. 0x%x\n", cmd);
 				state = state_error;
 			}
 			break;
@@ -1037,14 +1040,15 @@ via_verify_command_stream(const uint32_t
 }
 
 int
-via_parse_command_stream(struct drm_device * dev, const uint32_t * buf,
+via_parse_command_stream(struct drm_device *dev, const uint32_t *buf,
 			 unsigned int size)
 {
 
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
 	uint32_t cmd;
 	const uint32_t *buf_end = buf + (size >> 2);
-	verifier_state_t state = state_command;
+	enum verifier_state state = state_command;
 	int fire_count = 0;
 
 	while (buf < buf_end) {
@@ -1065,7 +1069,8 @@ via_parse_command_stream(struct drm_devi
 			state = via_parse_vheader6(dev_priv, &buf, buf_end);
 			break;
 		case state_command:
-			if (HALCYON_HEADER2 == (cmd = *buf))
+			cmd = *buf;
+			if (HALCYON_HEADER2 == cmd)
 				state = state_header2;
 			else if ((cmd & HALCYON_HEADER1MASK) == HALCYON_HEADER1)
 				state = state_header1;
@@ -1074,9 +1079,8 @@ via_parse_command_stream(struct drm_devi
 			else if ((cmd & VIA_VIDEOMASK) == VIA_VIDEO_HEADER6)
 				state = state_vheader6;
 			else {
-				DRM_ERROR
-				    ("Invalid / Unimplemented DMA HEADER command. 0x%x\n",
-				     cmd);
+				DRM_ERROR("Invalid / Unimplemented DMA \
+					HEADER command. 0x%x\n", cmd);
 				state = state_error;
 			}
 			break;
@@ -1085,32 +1089,31 @@ via_parse_command_stream(struct drm_devi
 			return -EINVAL;
 		}
 	}
-	if (state == state_error) {
+	if (state == state_error)
 		return -EINVAL;
-	}
+
 	return 0;
 }
 
 static void
-setup_hazard_table(hz_init_t init_table[], hazard_t table[], int size)
+setup_hazard_table(struct hz_init init_table[], enum hazard table[], int size)
 {
 	int i;
 
-	for (i = 0; i < 256; ++i) {
+	for (i = 0; i < 256; ++i)
 		table[i] = forbidden_command;
-	}
 
-	for (i = 0; i < size; ++i) {
+	for (i = 0; i < size; ++i)
 		table[init_table[i].code] = init_table[i].hz;
-	}
+
 }
 
 void via_init_command_verifier(void)
 {
 	setup_hazard_table(init_table1, table1,
-			   sizeof(init_table1) / sizeof(hz_init_t));
+			   sizeof(init_table1) / sizeof(struct hz_init));
 	setup_hazard_table(init_table2, table2,
-			   sizeof(init_table2) / sizeof(hz_init_t));
+			   sizeof(init_table2) / sizeof(struct hz_init));
 	setup_hazard_table(init_table3, table3,
-			   sizeof(init_table3) / sizeof(hz_init_t));
+			   sizeof(init_table3) / sizeof(struct hz_init));
 }
--- a/drivers/char/drm/via_verifier.h
+++ b/drivers/char/drm/via_verifier.h
@@ -1,39 +1,39 @@
 /*
- * Copyright 2004 The Unichrome Project. All Rights Reserved.
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation
- * the rights to use, copy, modify, merge, publish, distribute, sub license,
- * and/or sell copies of the Software, and to permit persons to whom the
- * Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice (including the
- * next paragraph) shall be included in all copies or substantial portions
- * of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
- * THE UNICHROME PROJECT, AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
- * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
- * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
- * DEALINGS IN THE SOFTWARE.
- *
- * Author: Thomas Hellström 2004.
- */
+* Copyright 2004 The Unichrome Project. All Rights Reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sub license,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright notice and this permission notice (including the
+* next paragraph) shall be included in all copies or substantial portions
+* of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+* THE UNICHROME PROJECT, AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,
+* DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+* OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR
+* THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+*
+* Author: Thomas Hellström 2004.
+*/
 
 #ifndef _VIA_VERIFIER_H_
 #define _VIA_VERIFIER_H_
 
-typedef enum {
+enum  drm_via_sequence {
 	no_sequence = 0,
 	z_address,
 	dest_address,
 	tex_address
-} drm_via_sequence_t;
+};
 
-typedef struct {
+struct drm_via_state {
 	unsigned texture;
 	uint32_t z_addr;
 	uint32_t d_addr;
@@ -44,7 +44,7 @@ typedef struct {
 	uint32_t tex_level_hi[2];
 	uint32_t tex_palette_size[2];
 	uint32_t tex_npot[2];
-	drm_via_sequence_t unfinished;
+	enum drm_via_sequence unfinished;
 	int agp_texture;
 	int multitex;
 	struct drm_device *dev;
@@ -52,11 +52,11 @@ typedef struct {
 	uint32_t vertex_count;
 	int agp;
 	const uint32_t *buf_start;
-} drm_via_state_t;
+};
 
-extern int via_verify_command_stream(const uint32_t * buf, unsigned int size,
-				     struct drm_device * dev, int agp);
-extern int via_parse_command_stream(struct drm_device *dev, const uint32_t *buf,
-				    unsigned int size);
+extern int via_verify_command_stream(const uint32_t *buf,
+	unsigned int size, struct drm_device *dev, int agp);
+extern int via_parse_command_stream(struct drm_device *dev,
+	const uint32_t *buf, unsigned int size);
 
 #endif
--- a/drivers/char/drm/via_video.c
+++ b/drivers/char/drm/via_video.c
@@ -1,35 +1,35 @@
 /*
- * Copyright 2005 Thomas Hellstrom. All Rights Reserved.
- *
- * Permission is hereby granted, free of charge, to any person obtaining a
- * copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation
- * the rights to use, copy, modify, merge, publish, distribute, sub license,
- * and/or sell copies of the Software, and to permit persons to whom the
- * Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice (including the
- * next paragraph) shall be included in all copies or substantial portions
- * of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
- * THE AUTHOR(S), AND/OR THE COPYRIGHT HOLDER(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
- * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
- * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
- * DEALINGS IN THE SOFTWARE.
- *
- * Author: Thomas Hellstrom 2005.
- *
- * Video and XvMC related functions.
- */
+* Copyright 2005 Thomas Hellstrom. All Rights Reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sub license,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright notice and this permission notice (including the
+* next paragraph) shall be included in all copies or substantial portions
+* of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+* THE AUTHOR(S), AND/OR THE COPYRIGHT HOLDER(S) BE LIABLE FOR ANY CLAIM, DAMAGES
+* OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+* ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*
+* Author: Thomas Hellstrom 2005.
+*
+* Video and XvMC related functions.
+*/
 
 #include "drmP.h"
 #include "via_drm.h"
 #include "via_drv.h"
 
-void via_init_futex(drm_via_private_t * dev_priv)
+void via_init_futex(struct drm_via_private *dev_priv)
 {
 	unsigned int i;
 
@@ -41,11 +41,11 @@ void via_init_futex(drm_via_private_t * 
 	}
 }
 
-void via_cleanup_futex(drm_via_private_t * dev_priv)
+void via_cleanup_futex(struct drm_via_private *dev_priv)
 {
 }
 
-void via_release_futex(drm_via_private_t * dev_priv, int context)
+void via_release_futex(struct drm_via_private *dev_priv, int context)
 {
 	unsigned int i;
 	volatile int *lock;
@@ -57,20 +57,22 @@ void via_release_futex(drm_via_private_t
 		lock = (volatile int *)XVMCLOCKPTR(dev_priv->sarea_priv, i);
 		if ((_DRM_LOCKING_CONTEXT(*lock) == context)) {
 			if (_DRM_LOCK_IS_HELD(*lock)
-			    && (*lock & _DRM_LOCK_CONT)) {
+			    && (*lock & _DRM_LOCK_CONT))
 				DRM_WAKEUP(&(dev_priv->decoder_queue[i]));
-			}
+
 			*lock = 0;
 		}
 	}
 }
 
-int via_decoder_futex(struct drm_device *dev, void *data, struct drm_file *file_priv)
+int via_decoder_futex(struct drm_device *dev, void *data,
+	struct drm_file *file_priv)
 {
-	drm_via_futex_t *fx = data;
+	struct drm_via_futex *fx = data;
 	volatile int *lock;
-	drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
-	drm_via_sarea_t *sAPriv = dev_priv->sarea_priv;
+	struct drm_via_private *dev_priv =
+		(struct drm_via_private *) dev->dev_private;
+	struct drm_via_sarea *sAPriv = dev_priv->sarea_priv;
 	int ret = 0;
 
 	DRM_DEBUG("\n");
