From sarah.a.sharp@linux.intel.com  Fri May  1 14:57:15 2009
From: Greg Kroah-Hartman <gregkh@suse.de>
Date: Wed, 29 Apr 2009 19:14:08 -0700
Subject: USB: xhci: fix lots of compiler warnings.
To: Greg KH <greg@kroah.com>
Message-ID: <20090430021408.GA31332@gamba.jf.intel.com>
Content-Disposition: inline

From: Greg Kroah-Hartman <gregkh@suse.de>

Turns out someone never built this code on a 64bit platform.

Someone owes me a beer...

Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
Cc: Sarah Sharp <sarah.a.sharp@linux.intel.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

---
 drivers/usb/host/xhci-dbg.c  |  180 ++++++++++++++++++++-----------------------
 drivers/usb/host/xhci-hcd.c  |   37 ++++----
 drivers/usb/host/xhci-mem.c  |   64 +++++++--------
 drivers/usb/host/xhci-ring.c |   72 ++++++++---------
 4 files changed, 172 insertions(+), 181 deletions(-)

--- a/drivers/usb/host/xhci-dbg.c
+++ b/drivers/usb/host/xhci-dbg.c
@@ -30,12 +30,11 @@ void xhci_dbg_regs(struct xhci_hcd *xhci
 {
 	u32 temp;
 
-	xhci_dbg(xhci, "// xHCI capability registers at 0x%x:\n",
-			(unsigned int) xhci->cap_regs);
+	xhci_dbg(xhci, "// xHCI capability registers at %p:\n",
+			xhci->cap_regs);
 	temp = xhci_readl(xhci, &xhci->cap_regs->hc_capbase);
-	xhci_dbg(xhci, "// @%x = 0x%x (CAPLENGTH AND HCIVERSION)\n",
-			(unsigned int) &xhci->cap_regs->hc_capbase,
-			(unsigned int) temp);
+	xhci_dbg(xhci, "// @%p = 0x%x (CAPLENGTH AND HCIVERSION)\n",
+			&xhci->cap_regs->hc_capbase, temp);
 	xhci_dbg(xhci, "//   CAPLENGTH: 0x%x\n",
 			(unsigned int) HC_LENGTH(temp));
 #if 0
@@ -43,29 +42,24 @@ void xhci_dbg_regs(struct xhci_hcd *xhci
 			(unsigned int) HC_VERSION(temp));
 #endif
 
-	xhci_dbg(xhci, "// xHCI operational registers at 0x%x:\n",
-			(unsigned int) xhci->op_regs);
+	xhci_dbg(xhci, "// xHCI operational registers at %p:\n", xhci->op_regs);
 
 	temp = xhci_readl(xhci, &xhci->cap_regs->run_regs_off);
-	xhci_dbg(xhci, "// @%x = 0x%x RTSOFF\n",
-			(unsigned int) &xhci->cap_regs->run_regs_off,
+	xhci_dbg(xhci, "// @%p = 0x%x RTSOFF\n",
+			&xhci->cap_regs->run_regs_off,
 			(unsigned int) temp & RTSOFF_MASK);
-	xhci_dbg(xhci, "// xHCI runtime registers at 0x%x:\n",
-			(unsigned int) xhci->run_regs);
+	xhci_dbg(xhci, "// xHCI runtime registers at %p:\n", xhci->run_regs);
 
 	temp = xhci_readl(xhci, &xhci->cap_regs->db_off);
-	xhci_dbg(xhci, "// @%x = 0x%x DBOFF\n",
-			(unsigned int) &xhci->cap_regs->db_off, temp);
-	xhci_dbg(xhci, "// Doorbell array at 0x%x:\n",
-			(unsigned int) xhci->dba);
+	xhci_dbg(xhci, "// @%p = 0x%x DBOFF\n", &xhci->cap_regs->db_off, temp);
+	xhci_dbg(xhci, "// Doorbell array at %p:\n", xhci->dba);
 }
 
 void xhci_print_cap_regs(struct xhci_hcd *xhci)
 {
 	u32 temp;
 
-	xhci_dbg(xhci, "xHCI capability registers at 0x%x:\n",
-			(unsigned int) xhci->cap_regs);
+	xhci_dbg(xhci, "xHCI capability registers at %p:\n", xhci->cap_regs);
 
 	temp = xhci_readl(xhci, &xhci->cap_regs->hc_capbase);
 	xhci_dbg(xhci, "CAPLENGTH AND HCIVERSION 0x%x:\n",
@@ -146,8 +140,7 @@ void xhci_print_status(struct xhci_hcd *
 
 void xhci_print_op_regs(struct xhci_hcd *xhci)
 {
-	xhci_dbg(xhci, "xHCI operational registers at 0x%x:\n",
-			(unsigned int) xhci->op_regs);
+	xhci_dbg(xhci, "xHCI operational registers at %p:\n", xhci->op_regs);
 	xhci_print_command_reg(xhci);
 	xhci_print_status(xhci);
 }
@@ -168,9 +161,8 @@ void xhci_print_ports(struct xhci_hcd *x
 	addr = &xhci->op_regs->port_status_base;
 	for (i = 0; i < ports; i++) {
 		for (j = 0; j < NUM_PORT_REGS; ++j) {
-			xhci_dbg(xhci, "0x%x port %s reg = 0x%x\n",
-					(unsigned int) addr,
-					names[j],
+			xhci_dbg(xhci, "%p port %s reg = 0x%x\n",
+					addr, names[j],
 					(unsigned int) xhci_readl(xhci, addr));
 			addr++;
 		}
@@ -187,46 +179,46 @@ void xhci_print_ir_set(struct xhci_hcd *
 	if (temp == XHCI_INIT_VALUE)
 		return;
 
-	xhci_dbg(xhci, "  0x%x: ir_set[%i]\n", (unsigned int) ir_set, set_num);
+	xhci_dbg(xhci, "  %p: ir_set[%i]\n", ir_set, set_num);
 
-	xhci_dbg(xhci, "  0x%x: ir_set.pending = 0x%x\n",
-			(unsigned int) addr, (unsigned int) temp);
+	xhci_dbg(xhci, "  %p: ir_set.pending = 0x%x\n", addr,
+			(unsigned int)temp);
 
 	addr = &ir_set->irq_control;
 	temp = xhci_readl(xhci, addr);
-	xhci_dbg(xhci, "  0x%x: ir_set.control = 0x%x\n",
-			(unsigned int) addr, (unsigned int) temp);
+	xhci_dbg(xhci, "  %p: ir_set.control = 0x%x\n", addr,
+			(unsigned int)temp);
 
 	addr = &ir_set->erst_size;
 	temp = xhci_readl(xhci, addr);
-	xhci_dbg(xhci, "  0x%x: ir_set.erst_size = 0x%x\n",
-			(unsigned int) addr, (unsigned int) temp);
+	xhci_dbg(xhci, "  %p: ir_set.erst_size = 0x%x\n", addr,
+			(unsigned int)temp);
 
 	addr = &ir_set->rsvd;
 	temp = xhci_readl(xhci, addr);
 	if (temp != XHCI_INIT_VALUE)
-		xhci_dbg(xhci, "  WARN: 0x%x: ir_set.rsvd = 0x%x\n",
-				(unsigned int) addr, (unsigned int) temp);
+		xhci_dbg(xhci, "  WARN: %p: ir_set.rsvd = 0x%x\n",
+				addr, (unsigned int)temp);
 
 	addr = &ir_set->erst_base[0];
 	temp = xhci_readl(xhci, addr);
-	xhci_dbg(xhci, "  0x%x: ir_set.erst_base[0] = 0x%x\n",
-			(unsigned int) addr, (unsigned int) temp);
+	xhci_dbg(xhci, "  %p: ir_set.erst_base[0] = 0x%x\n",
+			addr, (unsigned int) temp);
 
 	addr = &ir_set->erst_base[1];
 	temp = xhci_readl(xhci, addr);
-	xhci_dbg(xhci, "  0x%x: ir_set.erst_base[1] = 0x%x\n",
-			(unsigned int) addr, (unsigned int) temp);
+	xhci_dbg(xhci, "  %p: ir_set.erst_base[1] = 0x%x\n",
+			addr, (unsigned int) temp);
 
 	addr = &ir_set->erst_dequeue[0];
 	temp = xhci_readl(xhci, addr);
-	xhci_dbg(xhci, "  0x%x: ir_set.erst_dequeue[0] = 0x%x\n",
-			(unsigned int) addr, (unsigned int) temp);
+	xhci_dbg(xhci, "  %p: ir_set.erst_dequeue[0] = 0x%x\n",
+			addr, (unsigned int) temp);
 
 	addr = &ir_set->erst_dequeue[1];
 	temp = xhci_readl(xhci, addr);
-	xhci_dbg(xhci, "  0x%x: ir_set.erst_dequeue[1] = 0x%x\n",
-			(unsigned int) addr, (unsigned int) temp);
+	xhci_dbg(xhci, "  %p: ir_set.erst_dequeue[1] = 0x%x\n",
+			addr, (unsigned int) temp);
 }
 
 void xhci_print_run_regs(struct xhci_hcd *xhci)
@@ -234,17 +226,16 @@ void xhci_print_run_regs(struct xhci_hcd
 	u32 temp;
 	int i;
 
-	xhci_dbg(xhci, "xHCI runtime registers at 0x%x:\n",
-			(unsigned int) xhci->run_regs);
+	xhci_dbg(xhci, "xHCI runtime registers at %p:\n", xhci->run_regs);
 	temp = xhci_readl(xhci, &xhci->run_regs->microframe_index);
-	xhci_dbg(xhci, "  0x%x: Microframe index = 0x%x\n",
-			(unsigned int) &xhci->run_regs->microframe_index,
+	xhci_dbg(xhci, "  %p: Microframe index = 0x%x\n",
+			&xhci->run_regs->microframe_index,
 			(unsigned int) temp);
 	for (i = 0; i < 7; ++i) {
 		temp = xhci_readl(xhci, &xhci->run_regs->rsvd[i]);
 		if (temp != XHCI_INIT_VALUE)
-			xhci_dbg(xhci, "  WARN: 0x%x: Rsvd[%i] = 0x%x\n",
-					(unsigned int) &xhci->run_regs->rsvd[i],
+			xhci_dbg(xhci, "  WARN: %p: Rsvd[%i] = 0x%x\n",
+					&xhci->run_regs->rsvd[i],
 					i, (unsigned int) temp);
 	}
 }
@@ -347,14 +338,16 @@ void xhci_debug_segment(struct xhci_hcd 
 
 void xhci_dbg_ring_ptrs(struct xhci_hcd *xhci, struct xhci_ring *ring)
 {
-	xhci_dbg(xhci, "Ring deq = 0x%x (virt), 0x%x (dma)\n",
-			(unsigned int) ring->dequeue,
-			trb_virt_to_dma(ring->deq_seg, ring->dequeue));
+	xhci_dbg(xhci, "Ring deq = %p (virt), 0x%llx (dma)\n",
+			ring->dequeue,
+			(unsigned long long)trb_virt_to_dma(ring->deq_seg,
+							    ring->dequeue));
 	xhci_dbg(xhci, "Ring deq updated %u times\n",
 			ring->deq_updates);
-	xhci_dbg(xhci, "Ring enq = 0x%x (virt), 0x%x (dma)\n",
-			(unsigned int) ring->enqueue,
-			trb_virt_to_dma(ring->enq_seg, ring->enqueue));
+	xhci_dbg(xhci, "Ring enq = %p (virt), 0x%llx (dma)\n",
+			ring->enqueue,
+			(unsigned long long)trb_virt_to_dma(ring->enq_seg,
+							    ring->enqueue));
 	xhci_dbg(xhci, "Ring enq updated %u times\n",
 			ring->enq_updates);
 }
@@ -418,42 +411,42 @@ void xhci_dbg_ctx(struct xhci_hcd *xhci,
 	/* Fields are 32 bits wide, DMA addresses are in bytes */
 	int field_size = 32 / 8;
 
-	xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - drop flags\n",
-			(unsigned int) &ctx->drop_flags,
-			dma, ctx->drop_flags);
+	xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - drop flags\n",
+			&ctx->drop_flags, (unsigned long long)dma,
+			ctx->drop_flags);
 	dma += field_size;
-	xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - add flags\n",
-			(unsigned int) &ctx->add_flags,
-			dma, ctx->add_flags);
+	xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - add flags\n",
+			&ctx->add_flags, (unsigned long long)dma,
+			ctx->add_flags);
 	dma += field_size;
 	for (i = 0; i > 6; ++i) {
-		xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - rsvd[%d]\n",
-				(unsigned int) &ctx->rsvd[i],
-				dma, ctx->rsvd[i], i);
+		xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - rsvd[%d]\n",
+				&ctx->rsvd[i], (unsigned long long)dma,
+				ctx->rsvd[i], i);
 		dma += field_size;
 	}
 
 	xhci_dbg(xhci, "Slot Context:\n");
-	xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - dev_info\n",
-			(unsigned int) &ctx->slot.dev_info,
-			dma, ctx->slot.dev_info);
+	xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - dev_info\n",
+			&ctx->slot.dev_info,
+			(unsigned long long)dma, ctx->slot.dev_info);
 	dma += field_size;
-	xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - dev_info2\n",
-			(unsigned int) &ctx->slot.dev_info2,
-			dma, ctx->slot.dev_info2);
+	xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - dev_info2\n",
+			&ctx->slot.dev_info2,
+			(unsigned long long)dma, ctx->slot.dev_info2);
 	dma += field_size;
-	xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - tt_info\n",
-			(unsigned int) &ctx->slot.tt_info,
-			dma, ctx->slot.tt_info);
+	xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - tt_info\n",
+			&ctx->slot.tt_info,
+			(unsigned long long)dma, ctx->slot.tt_info);
 	dma += field_size;
-	xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - dev_state\n",
-			(unsigned int) &ctx->slot.dev_state,
-			dma, ctx->slot.dev_state);
+	xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - dev_state\n",
+			&ctx->slot.dev_state,
+			(unsigned long long)dma, ctx->slot.dev_state);
 	dma += field_size;
 	for (i = 0; i > 4; ++i) {
-		xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - rsvd[%d]\n",
-				(unsigned int) &ctx->slot.reserved[i],
-				dma, ctx->slot.reserved[i], i);
+		xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - rsvd[%d]\n",
+				&ctx->slot.reserved[i], (unsigned long long)dma,
+				ctx->slot.reserved[i], i);
 		dma += field_size;
 	}
 
@@ -461,30 +454,31 @@ void xhci_dbg_ctx(struct xhci_hcd *xhci,
 		last_ep_ctx = last_ep + 1;
 	for (i = 0; i < last_ep_ctx; ++i) {
 		xhci_dbg(xhci, "Endpoint %02d Context:\n", i);
-		xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - ep_info\n",
-				(unsigned int) &ctx->ep[i].ep_info,
-				dma, ctx->ep[i].ep_info);
+		xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - ep_info\n",
+				&ctx->ep[i].ep_info,
+				(unsigned long long)dma, ctx->ep[i].ep_info);
 		dma += field_size;
-		xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - ep_info2\n",
-				(unsigned int) &ctx->ep[i].ep_info2,
-				dma, ctx->ep[i].ep_info2);
+		xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - ep_info2\n",
+				&ctx->ep[i].ep_info2,
+				(unsigned long long)dma, ctx->ep[i].ep_info2);
 		dma += field_size;
-		xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - deq[0]\n",
-				(unsigned int) &ctx->ep[i].deq[0],
-				dma, ctx->ep[i].deq[0]);
+		xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - deq[0]\n",
+				&ctx->ep[i].deq[0],
+				(unsigned long long)dma, ctx->ep[i].deq[0]);
 		dma += field_size;
-		xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - deq[1]\n",
-				(unsigned int) &ctx->ep[i].deq[1],
-				dma, ctx->ep[i].deq[1]);
+		xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - deq[1]\n",
+				&ctx->ep[i].deq[1],
+				(unsigned long long)dma, ctx->ep[i].deq[1]);
 		dma += field_size;
-		xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - tx_info\n",
-				(unsigned int) &ctx->ep[i].tx_info,
-				dma, ctx->ep[i].tx_info);
+		xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - tx_info\n",
+				&ctx->ep[i].tx_info,
+				(unsigned long long)dma, ctx->ep[i].tx_info);
 		dma += field_size;
 		for (j = 0; j < 3; ++j) {
-			xhci_dbg(xhci, "@%08x (virt) @%08x (dma) %#08x - rsvd[%d]\n",
-					(unsigned int) &ctx->ep[i].reserved[j],
-					dma, ctx->ep[i].reserved[j], j);
+			xhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - rsvd[%d]\n",
+					&ctx->ep[i].reserved[j],
+					(unsigned long long)dma,
+					ctx->ep[i].reserved[j], j);
 			dma += field_size;
 		}
 	}
--- a/drivers/usb/host/xhci-hcd.c
+++ b/drivers/usb/host/xhci-hcd.c
@@ -397,10 +397,8 @@ int xhci_run(struct usb_hcd *hcd)
 	xhci_writel(xhci, temp, &xhci->op_regs->command);
 
 	temp = xhci_readl(xhci, &xhci->ir_set->irq_pending);
-	xhci_dbg(xhci, "// Enabling event ring interrupter 0x%x"
-			" by writing 0x%x to irq_pending\n",
-			(unsigned int) xhci->ir_set,
-			(unsigned int) ER_IRQ_ENABLE(temp));
+	xhci_dbg(xhci, "// Enabling event ring interrupter %p by writing 0x%x to irq_pending\n",
+			xhci->ir_set, (unsigned int) ER_IRQ_ENABLE(temp));
 	xhci_writel(xhci, ER_IRQ_ENABLE(temp),
 			&xhci->ir_set->irq_pending);
 	xhci_print_ir_set(xhci, xhci->ir_set, 0);
@@ -431,8 +429,7 @@ int xhci_run(struct usb_hcd *hcd)
 	xhci_writel(xhci, temp, &xhci->op_regs->command);
 	/* Flush PCI posted writes */
 	temp = xhci_readl(xhci, &xhci->op_regs->command);
-	xhci_dbg(xhci, "// @%x = 0x%x\n",
-			(unsigned int) &xhci->op_regs->command, temp);
+	xhci_dbg(xhci, "// @%p = 0x%x\n", &xhci->op_regs->command, temp);
 	if (doorbell)
 		(*doorbell)(xhci);
 
@@ -660,7 +657,7 @@ int xhci_urb_dequeue(struct usb_hcd *hcd
 	if (ret || !urb->hcpriv)
 		goto done;
 
-	xhci_dbg(xhci, "Cancel URB 0x%x\n", (unsigned int) urb);
+	xhci_dbg(xhci, "Cancel URB %p\n", urb);
 	ep_index = xhci_get_endpoint_index(&urb->ep->desc);
 	ep_ring = xhci->devs[urb->dev->slot_id]->ep_rings[ep_index];
 	td = (struct xhci_td *) urb->hcpriv;
@@ -702,10 +699,10 @@ int xhci_drop_endpoint(struct usb_hcd *h
 	int ret;
 
 	ret = xhci_check_args(hcd, udev, ep, 1, __func__);
-	xhci_dbg(xhci, "%s called for udev %#x\n", __func__, (unsigned int) udev);
 	if (ret <= 0)
 		return ret;
 	xhci = hcd_to_xhci(hcd);
+	xhci_dbg(xhci, "%s called for udev %p\n", __func__, udev);
 
 	drop_flag = xhci_get_endpoint_flag(&ep->desc);
 	if (drop_flag == SLOT_FLAG || drop_flag == EP0_FLAG) {
@@ -730,8 +727,8 @@ int xhci_drop_endpoint(struct usb_hcd *h
 	 */
 	if ((ep_ctx->ep_info & EP_STATE_MASK) == EP_STATE_DISABLED ||
 			in_ctx->drop_flags & xhci_get_endpoint_flag(&ep->desc)) {
-		xhci_warn(xhci, "xHCI %s called with disabled ep %#x\n",
-				__func__, (unsigned int) ep);
+		xhci_warn(xhci, "xHCI %s called with disabled ep %p\n",
+				__func__, ep);
 		spin_unlock_irqrestore(&xhci->lock, flags);
 		return 0;
 	}
@@ -817,8 +814,8 @@ int xhci_add_endpoint(struct usb_hcd *hc
 	 * ignore this request.
 	 */
 	if (in_ctx->add_flags & xhci_get_endpoint_flag(&ep->desc)) {
-		xhci_warn(xhci, "xHCI %s called with enabled ep %#x\n",
-				__func__, (unsigned int) ep);
+		xhci_warn(xhci, "xHCI %s called with enabled ep %p\n",
+				__func__, ep);
 		spin_unlock_irqrestore(&xhci->lock, flags);
 		return 0;
 	}
@@ -904,7 +901,7 @@ int xhci_check_bandwidth(struct usb_hcd 
 		spin_unlock_irqrestore(&xhci->lock, flags);
 		return -EINVAL;
 	}
-	xhci_dbg(xhci, "%s called for udev %#x\n", __func__, (unsigned int) udev);
+	xhci_dbg(xhci, "%s called for udev %p\n", __func__, udev);
 	virt_dev = xhci->devs[udev->slot_id];
 
 	/* See section 4.6.6 - A0 = 1; A1 = D0 = D1 = 0 */
@@ -1009,7 +1006,7 @@ void xhci_reset_bandwidth(struct usb_hcd
 		spin_unlock_irqrestore(&xhci->lock, flags);
 		return;
 	}
-	xhci_dbg(xhci, "%s called for udev %#x\n", __func__, (unsigned int) udev);
+	xhci_dbg(xhci, "%s called for udev %p\n", __func__, udev);
 	virt_dev = xhci->devs[udev->slot_id];
 	/* Free any rings allocated for added endpoints */
 	for (i = 0; i < 31; ++i) {
@@ -1184,16 +1181,16 @@ int xhci_address_device(struct usb_hcd *
 	xhci_dbg(xhci, "Op regs DCBAA ptr[0] = %#08x\n", temp);
 	temp = xhci_readl(xhci, &xhci->op_regs->dcbaa_ptr[1]);
 	xhci_dbg(xhci, "Op regs DCBAA ptr[1] = %#08x\n", temp);
-	xhci_dbg(xhci, "Slot ID %d dcbaa entry[0] @%08x = %#08x\n",
+	xhci_dbg(xhci, "Slot ID %d dcbaa entry[0] @%p = %#08x\n",
 			udev->slot_id,
-			(unsigned int) &xhci->dcbaa->dev_context_ptrs[2*udev->slot_id],
+			&xhci->dcbaa->dev_context_ptrs[2*udev->slot_id],
 			xhci->dcbaa->dev_context_ptrs[2*udev->slot_id]);
-	xhci_dbg(xhci, "Slot ID %d dcbaa entry[1] @%08x = %#08x\n",
+	xhci_dbg(xhci, "Slot ID %d dcbaa entry[1] @%p = %#08x\n",
 			udev->slot_id,
-			(unsigned int) &xhci->dcbaa->dev_context_ptrs[2*udev->slot_id+1],
+			&xhci->dcbaa->dev_context_ptrs[2*udev->slot_id+1],
 			xhci->dcbaa->dev_context_ptrs[2*udev->slot_id+1]);
-	xhci_dbg(xhci, "Output Context DMA address = %#08x\n",
-			virt_dev->out_ctx_dma);
+	xhci_dbg(xhci, "Output Context DMA address = %#08llx\n",
+			(unsigned long long)virt_dev->out_ctx_dma);
 	xhci_dbg(xhci, "Slot ID %d Input Context:\n", udev->slot_id);
 	xhci_dbg_ctx(xhci, virt_dev->in_ctx, virt_dev->in_ctx_dma, 2);
 	xhci_dbg(xhci, "Slot ID %d Output Context:\n", udev->slot_id);
--- a/drivers/usb/host/xhci-mem.c
+++ b/drivers/usb/host/xhci-mem.c
@@ -40,16 +40,15 @@ static struct xhci_segment *xhci_segment
 	seg = kzalloc(sizeof *seg, flags);
 	if (!seg)
 		return 0;
-	xhci_dbg(xhci, "Allocating priv segment structure at 0x%x\n",
-			(unsigned int) seg);
+	xhci_dbg(xhci, "Allocating priv segment structure at %p\n", seg);
 
 	seg->trbs = dma_pool_alloc(xhci->segment_pool, flags, &dma);
 	if (!seg->trbs) {
 		kfree(seg);
 		return 0;
 	}
-	xhci_dbg(xhci, "// Allocating segment at 0x%x (virtual) 0x%x (DMA)\n",
-			(unsigned int) seg->trbs, (u32) dma);
+	xhci_dbg(xhci, "// Allocating segment at %p (virtual) 0x%llx (DMA)\n",
+			seg->trbs, (unsigned long long)dma);
 
 	memset(seg->trbs, 0, SEGMENT_SIZE);
 	seg->dma = dma;
@@ -63,14 +62,12 @@ static void xhci_segment_free(struct xhc
 	if (!seg)
 		return;
 	if (seg->trbs) {
-		xhci_dbg(xhci, "Freeing DMA segment at 0x%x"
-				" (virtual) 0x%x (DMA)\n",
-				(unsigned int) seg->trbs, (u32) seg->dma);
+		xhci_dbg(xhci, "Freeing DMA segment at %p (virtual) 0x%llx (DMA)\n",
+				seg->trbs, (unsigned long long)seg->dma);
 		dma_pool_free(xhci->segment_pool, seg->trbs, seg->dma);
 		seg->trbs = NULL;
 	}
-	xhci_dbg(xhci, "Freeing priv segment structure at 0x%x\n",
-			(unsigned int) seg);
+	xhci_dbg(xhci, "Freeing priv segment structure at %p\n", seg);
 	kfree(seg);
 }
 
@@ -98,8 +95,9 @@ static void xhci_link_segments(struct xh
 		val |= TRB_TYPE(TRB_LINK);
 		prev->trbs[TRBS_PER_SEGMENT-1].link.control = val;
 	}
-	xhci_dbg(xhci, "Linking segment 0x%x to segment 0x%x (DMA)\n",
-			prev->dma, next->dma);
+	xhci_dbg(xhci, "Linking segment 0x%llx to segment 0x%llx (DMA)\n",
+			(unsigned long long)prev->dma,
+			(unsigned long long)next->dma);
 }
 
 /* XXX: Do we need the hcd structure in all these functions? */
@@ -112,7 +110,7 @@ void xhci_ring_free(struct xhci_hcd *xhc
 		return;
 	first_seg = ring->first_seg;
 	seg = first_seg->next;
-	xhci_dbg(xhci, "Freeing ring at 0x%x\n", (unsigned int) ring);
+	xhci_dbg(xhci, "Freeing ring at %p\n", ring);
 	while (seg != first_seg) {
 		struct xhci_segment *next = seg->next;
 		xhci_segment_free(xhci, seg);
@@ -137,7 +135,7 @@ static struct xhci_ring *xhci_ring_alloc
 	struct xhci_segment	*prev;
 
 	ring = kzalloc(sizeof *(ring), flags);
-	xhci_dbg(xhci, "Allocating ring at 0x%x\n", (unsigned int) ring);
+	xhci_dbg(xhci, "Allocating ring at %p\n", ring);
 	if (!ring)
 		return 0;
 
@@ -169,8 +167,8 @@ static struct xhci_ring *xhci_ring_alloc
 		/* See section 4.9.2.1 and 6.4.4.1 */
 		prev->trbs[TRBS_PER_SEGMENT-1].link.control |= (LINK_TOGGLE);
 		xhci_dbg(xhci, "Wrote link toggle flag to"
-				" segment 0x%x (virtual), 0x%x (DMA)\n",
-				(unsigned int) prev, (u32) prev->dma);
+				" segment %p (virtual), 0x%llx (DMA)\n",
+				prev, (unsigned long long)prev->dma);
 	}
 	/* The ring is empty, so the enqueue pointer == dequeue pointer */
 	ring->enqueue = ring->first_seg->trbs;
@@ -242,7 +240,8 @@ int xhci_alloc_virt_device(struct xhci_h
 	if (!dev->out_ctx)
 		goto fail;
 	dev->out_ctx_dma = dma;
-	xhci_dbg(xhci, "Slot %d output ctx = 0x%x (dma)\n", slot_id, dma);
+	xhci_dbg(xhci, "Slot %d output ctx = 0x%llx (dma)\n", slot_id,
+			(unsigned long long)dma);
 	memset(dev->out_ctx, 0, sizeof(*dev->out_ctx));
 
 	/* Allocate the (input) device context for address device command */
@@ -250,7 +249,8 @@ int xhci_alloc_virt_device(struct xhci_h
 	if (!dev->in_ctx)
 		goto fail;
 	dev->in_ctx_dma = dma;
-	xhci_dbg(xhci, "Slot %d input ctx = 0x%x (dma)\n", slot_id, dma);
+	xhci_dbg(xhci, "Slot %d input ctx = 0x%llx (dma)\n", slot_id,
+			(unsigned long long)dma);
 	memset(dev->in_ctx, 0, sizeof(*dev->in_ctx));
 
 	/* Allocate endpoint 0 ring */
@@ -266,10 +266,10 @@ int xhci_alloc_virt_device(struct xhci_h
 	 */
 	xhci->dcbaa->dev_context_ptrs[2*slot_id] =
 		(u32) dev->out_ctx_dma + (32);
-	xhci_dbg(xhci, "Set slot id %d dcbaa entry 0x%x to 0x%x\n",
+	xhci_dbg(xhci, "Set slot id %d dcbaa entry %p to 0x%llx\n",
 			slot_id,
-			(unsigned int) &xhci->dcbaa->dev_context_ptrs[2*slot_id],
-			dev->out_ctx_dma);
+			&xhci->dcbaa->dev_context_ptrs[2*slot_id],
+			(unsigned long long)dev->out_ctx_dma);
 	xhci->dcbaa->dev_context_ptrs[2*slot_id + 1] = 0;
 
 	return 1;
@@ -339,7 +339,7 @@ int xhci_setup_addressable_virt_dev(stru
 		dev->in_ctx->slot.tt_info = udev->tt->hub->slot_id;
 		dev->in_ctx->slot.tt_info |= udev->ttport << 8;
 	}
-	xhci_dbg(xhci, "udev->tt = 0x%x\n", (unsigned int) udev->tt);
+	xhci_dbg(xhci, "udev->tt = %p\n", udev->tt);
 	xhci_dbg(xhci, "udev->ttport = 0x%x\n", udev->ttport);
 
 	/* Step 4 - ring already allocated */
@@ -643,8 +643,8 @@ int xhci_mem_init(struct xhci_hcd *xhci,
 		goto fail;
 	memset(xhci->dcbaa, 0, sizeof *(xhci->dcbaa));
 	xhci->dcbaa->dma = dma;
-	xhci_dbg(xhci, "// Device context base array address = 0x%x (DMA), 0x%x (virt)\n",
-			xhci->dcbaa->dma, (unsigned int) xhci->dcbaa);
+	xhci_dbg(xhci, "// Device context base array address = 0x%llx (DMA), %p (virt)\n",
+			(unsigned long long)xhci->dcbaa->dma, xhci->dcbaa);
 	xhci_writel(xhci, (u32) 0, &xhci->op_regs->dcbaa_ptr[1]);
 	xhci_writel(xhci, dma, &xhci->op_regs->dcbaa_ptr[0]);
 
@@ -668,8 +668,9 @@ int xhci_mem_init(struct xhci_hcd *xhci,
 	xhci->cmd_ring = xhci_ring_alloc(xhci, 1, true, flags);
 	if (!xhci->cmd_ring)
 		goto fail;
-	xhci_dbg(xhci, "Allocated command ring at 0x%x\n", (unsigned int) xhci->cmd_ring);
-	xhci_dbg(xhci, "First segment DMA is 0x%x\n", (unsigned int) xhci->cmd_ring->first_seg->dma);
+	xhci_dbg(xhci, "Allocated command ring at %p\n", xhci->cmd_ring);
+	xhci_dbg(xhci, "First segment DMA is 0x%llx\n",
+			(unsigned long long)xhci->cmd_ring->first_seg->dma);
 
 	/* Set the address in the Command Ring Control register */
 	val = xhci_readl(xhci, &xhci->op_regs->cmd_ring[0]);
@@ -705,15 +706,16 @@ int xhci_mem_init(struct xhci_hcd *xhci,
 			sizeof(struct xhci_erst_entry)*ERST_NUM_SEGS, &dma);
 	if (!xhci->erst.entries)
 		goto fail;
-	xhci_dbg(xhci, "// Allocated event ring segment table at 0x%x\n", dma);
+	xhci_dbg(xhci, "// Allocated event ring segment table at 0x%llx\n",
+			(unsigned long long)dma);
 
 	memset(xhci->erst.entries, 0, sizeof(struct xhci_erst_entry)*ERST_NUM_SEGS);
 	xhci->erst.num_entries = ERST_NUM_SEGS;
 	xhci->erst.erst_dma_addr = dma;
-	xhci_dbg(xhci, "Set ERST to 0; private num segs = %i, virt addr = 0x%x, dma addr = 0x%x\n",
+	xhci_dbg(xhci, "Set ERST to 0; private num segs = %i, virt addr = %p, dma addr = 0x%llx\n",
 			xhci->erst.num_entries,
-			(unsigned int) xhci->erst.entries,
-			xhci->erst.erst_dma_addr);
+			xhci->erst.entries,
+			(unsigned long long)xhci->erst.erst_dma_addr);
 
 	/* set ring base address and size for each segment table entry */
 	for (val = 0, seg = xhci->event_ring->first_seg; val < ERST_NUM_SEGS; val++) {
@@ -735,8 +737,8 @@ int xhci_mem_init(struct xhci_hcd *xhci,
 
 	xhci_dbg(xhci, "// Set ERST entries to point to event ring.\n");
 	/* set the segment table base address */
-	xhci_dbg(xhci, "// Set ERST base address for ir_set 0 = 0x%x\n",
-			xhci->erst.erst_dma_addr);
+	xhci_dbg(xhci, "// Set ERST base address for ir_set 0 = 0x%llx\n",
+			(unsigned long long)xhci->erst.erst_dma_addr);
 	xhci_writel(xhci, 0, &xhci->ir_set->erst_base[1]);
 	val = xhci_readl(xhci, &xhci->ir_set->erst_base[0]);
 	val &= ERST_PTR_MASK;
--- a/drivers/usb/host/xhci-ring.c
+++ b/drivers/usb/host/xhci-ring.c
@@ -74,12 +74,12 @@
 dma_addr_t trb_virt_to_dma(struct xhci_segment *seg,
 		union xhci_trb *trb)
 {
-	unsigned int offset;
+	dma_addr_t offset;
 
 	if (!seg || !trb || (void *) trb < (void *) seg->trbs)
 		return 0;
 	/* offset in bytes, since these are byte-addressable */
-	offset = (unsigned int) trb - (unsigned int) seg->trbs;
+	offset = trb - seg->trbs;
 	/* SEGMENT_SIZE in bytes, trbs are 16-byte aligned */
 	if (offset > SEGMENT_SIZE || (offset % sizeof(*trb)) != 0)
 		return 0;
@@ -145,8 +145,8 @@ static void inc_deq(struct xhci_hcd *xhc
 		if (consumer && last_trb_on_last_seg(xhci, ring, ring->deq_seg, next)) {
 			ring->cycle_state = (ring->cycle_state ? 0 : 1);
 			if (!in_interrupt())
-				xhci_dbg(xhci, "Toggle cycle state for ring 0x%x = %i\n",
-						(unsigned int) ring,
+				xhci_dbg(xhci, "Toggle cycle state for ring %p = %i\n",
+						ring,
 						(unsigned int) ring->cycle_state);
 		}
 		ring->deq_seg = ring->deq_seg->next;
@@ -195,8 +195,8 @@ static void inc_enq(struct xhci_hcd *xhc
 			if (last_trb_on_last_seg(xhci, ring, ring->enq_seg, next)) {
 				ring->cycle_state = (ring->cycle_state ? 0 : 1);
 				if (!in_interrupt())
-					xhci_dbg(xhci, "Toggle cycle state for ring 0x%x = %i\n",
-							(unsigned int) ring,
+					xhci_dbg(xhci, "Toggle cycle state for ring %p = %i\n",
+							ring,
 							(unsigned int) ring->cycle_state);
 			}
 		}
@@ -387,12 +387,12 @@ void td_to_noop(struct xhci_hcd *xhci, s
 			 */
 			cur_trb->generic.field[3] &= ~TRB_CHAIN;
 			xhci_dbg(xhci, "Cancel (unchain) link TRB\n");
-			xhci_dbg(xhci, "Address = 0x%x (0x%x dma); "
-					"in seg 0x%x (0x%x dma)\n",
-					(unsigned int) cur_trb,
-					trb_virt_to_dma(cur_seg, cur_trb),
-					(unsigned int) cur_seg,
-					cur_seg->dma);
+			xhci_dbg(xhci, "Address = %p (0x%llx dma); "
+					"in seg %p (0x%llx dma)\n",
+					cur_trb,
+					(unsigned long long)trb_virt_to_dma(cur_seg, cur_trb),
+					cur_seg,
+					(unsigned long long)cur_seg->dma);
 		} else {
 			cur_trb->generic.field[0] = 0;
 			cur_trb->generic.field[1] = 0;
@@ -400,12 +400,12 @@ void td_to_noop(struct xhci_hcd *xhci, s
 			/* Preserve only the cycle bit of this TRB */
 			cur_trb->generic.field[3] &= TRB_CYCLE;
 			cur_trb->generic.field[3] |= TRB_TYPE(TRB_TR_NOOP);
-			xhci_dbg(xhci, "Cancel TRB 0x%x (0x%x dma) "
-					"in seg 0x%x (0x%x dma)\n",
-					(unsigned int) cur_trb,
-					trb_virt_to_dma(cur_seg, cur_trb),
-					(unsigned int) cur_seg,
-					cur_seg->dma);
+			xhci_dbg(xhci, "Cancel TRB %p (0x%llx dma) "
+					"in seg %p (0x%llx dma)\n",
+					cur_trb,
+					(unsigned long long)trb_virt_to_dma(cur_seg, cur_trb),
+					cur_seg,
+					(unsigned long long)cur_seg->dma);
 		}
 		if (cur_trb == cur_td->last_trb)
 			break;
@@ -456,9 +456,9 @@ static void handle_stopped_endpoint(stru
 	 */
 	list_for_each(entry, &ep_ring->cancelled_td_list) {
 		cur_td = list_entry(entry, struct xhci_td, cancelled_td_list);
-		xhci_dbg(xhci, "Cancelling TD starting at 0x%x, 0x%x (dma).\n",
-				(unsigned int) cur_td->first_trb,
-				trb_virt_to_dma(cur_td->start_seg, cur_td->first_trb));
+		xhci_dbg(xhci, "Cancelling TD starting at %p, 0x%llx (dma).\n",
+				cur_td->first_trb,
+				(unsigned long long)trb_virt_to_dma(cur_td->start_seg, cur_td->first_trb));
 		/*
 		 * If we stopped on the TD we need to cancel, then we have to
 		 * move the xHC endpoint ring dequeue pointer past this TD.
@@ -480,12 +480,12 @@ static void handle_stopped_endpoint(stru
 
 	/* If necessary, queue a Set Transfer Ring Dequeue Pointer command */
 	if (deq_state.new_deq_ptr && deq_state.new_deq_seg) {
-		xhci_dbg(xhci, "Set TR Deq Ptr cmd, new deq seg = 0x%x (0x%x dma), "
-				"new deq ptr = 0x%x (0x%x dma), new cycle = %u\n",
-				(unsigned int) deq_state.new_deq_seg,
-				deq_state.new_deq_seg->dma,
-				(unsigned int) deq_state.new_deq_ptr,
-				trb_virt_to_dma(deq_state.new_deq_seg, deq_state.new_deq_ptr),
+		xhci_dbg(xhci, "Set TR Deq Ptr cmd, new deq seg = %p (0x%llx dma), "
+				"new deq ptr = %p (0x%llx dma), new cycle = %u\n",
+				deq_state.new_deq_seg,
+				(unsigned long long)deq_state.new_deq_seg->dma,
+				deq_state.new_deq_ptr,
+				(unsigned long long)trb_virt_to_dma(deq_state.new_deq_seg, deq_state.new_deq_ptr),
 				deq_state.new_cycle_state);
 		queue_set_tr_deq(xhci, slot_id, ep_index,
 				deq_state.new_deq_seg,
@@ -522,8 +522,7 @@ static void handle_stopped_endpoint(stru
 		cur_td->urb->hcpriv = NULL;
 		usb_hcd_unlink_urb_from_ep(xhci_to_hcd(xhci), cur_td->urb);
 
-		xhci_dbg(xhci, "Giveback cancelled URB 0x%x\n",
-				(unsigned int) cur_td->urb);
+		xhci_dbg(xhci, "Giveback cancelled URB %p\n", cur_td->urb);
 		spin_unlock(&xhci->lock);
 		/* Doesn't matter what we pass for status, since the core will
 		 * just overwrite it (because the URB has been unlinked).
@@ -1183,9 +1182,9 @@ unsigned int count_sg_trbs_needed(struct
 			num_trbs++;
 			running_total += TRB_MAX_BUFF_SIZE;
 		}
-		xhci_dbg(xhci, " sg #%d: dma = %#x, len = %#x (%d), num_trbs = %d\n",
-				i, sg_dma_address(sg), len, len,
-				num_trbs - previous_total_trbs);
+		xhci_dbg(xhci, " sg #%d: dma = %#llx, len = %#x (%d), num_trbs = %d\n",
+				i, (unsigned long long)sg_dma_address(sg),
+				len, len, num_trbs - previous_total_trbs);
 
 		len = min_t(int, len, temp);
 		temp -= len;
@@ -1394,11 +1393,11 @@ int queue_bulk_tx(struct xhci_hcd *xhci,
 	/* FIXME: this doesn't deal with URB_ZERO_PACKET - need one more */
 
 	if (!in_interrupt())
-		dev_dbg(&urb->dev->dev, "ep %#x - urb len = %#x (%d), addr = %#x, num_trbs = %d\n",
+		dev_dbg(&urb->dev->dev, "ep %#x - urb len = %#x (%d), addr = %#llx, num_trbs = %d\n",
 				urb->ep->desc.bEndpointAddress,
 				urb->transfer_buffer_length,
 				urb->transfer_buffer_length,
-				urb->transfer_dma,
+				(unsigned long long)urb->transfer_dma,
 				num_trbs);
 
 	ret = xhci_prepare_transfer(xhci, xhci->devs[slot_id], ep_index,
@@ -1640,9 +1639,8 @@ static int queue_set_tr_deq(struct xhci_
 	addr = trb_virt_to_dma(deq_seg, deq_ptr);
 	if (addr == 0)
 		xhci_warn(xhci, "WARN Cannot submit Set TR Deq Ptr\n");
-		xhci_warn(xhci, "WARN deq seg = 0x%x, deq pt = 0x%x\n",
-				(unsigned int) deq_seg,
-				(unsigned int) deq_ptr);
+		xhci_warn(xhci, "WARN deq seg = %p, deq pt = %p\n",
+				deq_seg, deq_ptr);
 	return queue_command(xhci, (u32) addr | cycle_state, 0, 0,
 			trb_slot_id | trb_ep_index | type);
 }
